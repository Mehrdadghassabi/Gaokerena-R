% !TeX root=../main.tex
\chapter{بررسی کار های پیشین}
\section{مقدمه}
همان‌طور که پیش‌تر اشاره شد، علیرغم پیشرفت‌های چشمگیر در توسعه مدل‌های زبانی پزشکی به زبان انگلیسی، مانند توسعه و معرفی مدل‌های
\lr{MedPalm}
\cite{b22}
\cite{b23}
یا مدل
\lr{Med-Gemini}
\cite{b24}
،متأسفانه در حوزه زبان فارسی هنوز کار چندانی در این زمینه انجام نشده است. این مسئله بدین معناست که ما در حوزه زبان فارسی تقریبا با یک کاغذ سفید روبه‌رو هستیم. در این پایان‌نامه تلاش شده است تا قدمی رو به جلو در جهت توسعه مدل‌های زبانی پزشکی برای زبان فارسی برداشته شود.

در ادامه، به بررسی کارهای پیشین انجام‌شده در حوزه زبان انگلیسی، حوزه زبان فارسی و مدل‌های دارای قابلیت دلیل‌آوری خواهیم پرداخت.
\section{کار های پیشین در حوزه زبان انگلیسی}
\subsection{مدل های
	\lr{MedPaLM}
}
مدل های 
\lr{MedPaLM}
یکی از مدل‌های زبانی پزشکی بزرگ 
\footnote{\lr{large medical language models}}
است که توسط تیم تحقیقاتی گوگل برای کاربرد های پزشکی توسعه داده شده است. این مدل با استفاده از داده‌های تخصصی پزشکی و بالینی آموزش دیده است. هدف اصلی این خانواده از مدل های زبانی پزشکی پاسخ‌گویی به پرسش‌های پزشکی با دقت بالا، کمک به پزشکان در تصمیم‌گیری‌های بالینی، و تسهیل دسترسی به اطلاعات پزشکی برای کاربران است. نسخه‌های مختلف این مدل، مانند
\lr{MedPaLM}
و
\lr{MedPaLM2}
، توانایی‌های قابل توجهی در درک و تحلیل زبان تخصصی پزشکی نشان داده‌اند و به عنوان یک ابزار نوین در حوزه هوش مصنوعی پزشکی شناخته می‌شوند. این مدل‌ها با استفاده از آزمون‌های استاندارد پزشکی (مانند
\lr{USMLE}) 
ارزیابی شده و توانسته‌اند عملکردی نزدیک به سطح متخصصین پزشکی ارائه دهند. مدل
\lr{MedPaLM2}
به عنوان یک گام مهم در جهت توسعه مدل‌های زبان تخصصی در حوزه سلامت و پزشکی شناخته می‌شود.
\subsection{مدل 
	\lr{ChatDoctor}
}
مدل
\lr{ChatDoctor}
\cite{b25}
یکی از برجسته‌ترین تلاش‌ها در حوزه توسعه مدل‌های زبانی پزشکی است که شباهت قابل توجهی به فاز نخست پایان‌نامه حاضر دارد. تیم توسعه‌دهنده این مدل، داده‌های آموزشی خود را از دو پلتفرم آنلاین پرسش و پاسخ پزشکی به نام‌های
\lr{HealthcareMagic}
و
\lr{iCliniq}
جمع‌آوری کرده‌اند. این تیم ابتدا بیش از دویست هزار جفت پرسش و پاسخ پزشکی از این منابع گردآوری کرده و سپس با اعمال فیلترهایی بر اساس طول و کیفیت پاسخ‌ها، مجموعه‌ای با کیفیت بالا شامل صد هزار جفت پرسش و پاسخ نهایی ایجاد کرده‌اند. داده‌های مذکور به‌عنوان پایه‌ای برای آموزش و تنظیم دقیق
\footnote{\lr{fine-tuning}}
مدل
\lr{LLaMa}
\cite{b26}
مورد استفاده قرار گرفته‌اند تا مدلی توانمند در تولید اطلاعات پزشکی دقیق و مرتبط ایجاد شود.

علاوه بر این، این مدل از رویکرد تولید مبتنی بر بازیابی اطلاعات
\footnote{\lr{retrieval augmented generation}}
بهره برده است. این رویکرد به مدل امکان می‌دهد تا به اطلاعات جدید و خارجی دسترسی پیدا کرده و آن‌ها را به‌طور مؤثر در پاسخ‌های خود ادغام کند. چنین رویکردی موجب ارتقای عملکرد کلی سیستم شده و توانایی مدل در تولید پاسخ‌هایی دقیق‌تر و مرتبط‌تر را به‌طور چشمگیری بهبود بخشیده است.

\subsection{مدل های 
	\lr{Meerkat}
}
مدل‌های
\lr{Meerkat}
\cite{b27}
یکی دیگر از تلاش‌های برجسته در حوزه توسعه مدل‌های زبانی پزشکی است. این پروژه با استخراج زنجیره‌های تفکر
\footnote{\lr{chain of thought}}
از کتاب‌های درسی پزشکی و تنظیم دقیق یک مدل زبانی پایه با استفاده از این داده‌ها، همراه با مجموعه داده‌های مکمل دیگر، به وجود است.همانند فاز دوم پایان نامه حاضر هدف اصلی
\lr{Meerkat}
تمرکز بر فرآیندهای استدلالی است که در تصمیم‌گیری‌های پزشکی نقش دارند. این مدل تلاش کرده است تا نه تنها اطلاعات پزشکی دقیق ارائه دهد، بلکه فرآیندهای شناختی و تصمیم‌گیری متخصصان حوزه سلامت را شبیه‌سازی کند. به همین دلیل، 
\lr{Meerkat}
به عنوان مدلی برای تعاملات پیچیده‌تر و آگاهانه‌تر در حوزه پزشکی معرفی شده است.
\subsection{مدل 
	\lr{MedMobile}
}
\lr{MedMobile}
\cite{b28}
تلاشی دیگر در حوزه مدل‌های زبانی کوچک پزشکی است. برای توسعه این مدل زبانی کوچک، مدل
\lr{Phi-3-mini}
\cite{b29}
به عنوان مدل پایه
\footnote{\lr{baseline model}}
استفاده از ترکیبی از داده‌های مصنوعی و تولیدشده توسط انسان تنظیم دقیق
\footnote{\lr{fine tune}}
 شده است تا عملکردی بهینه و مناسب برای اجرا روی دستگاه‌های همراه مانند موبایل ارائه دهد. با تمرکز بر نیازهای خاص کاربران دستگاه های همراه، 
\lr{MedMobile}
تلاش کرده است مدلی کارآمد و مؤثر فراهم کند که دسترسی به اطلاعات پزشکی باکیفیت را در هر زمان و مکان به صورت محلی 
\footnote{\lr{local}}
ممکن می‌سازد.
\section{کار های پیشین در حوزه زبان فارسی}
همان‌طور که پیش‌تر اشاره شد، تحقیقات محدودی بر روی مدل‌های زبانی پزشکی فارسی تمرکز داشته‌اند که این امر نشان‌دهنده شکاف قابل توجهی در منابع موجود برای جامعه پزشکی فارسی‌زبان است. علاوه بر این، پژوهش‌های بسیار اندک موجود در این زمینه ، به طور کامل در مورد مجموعه داده‌ها، مدل‌ها و کدهای خود متن بسته
\footnote{\lr{closed-source}}
هستند.

از سوی دیگر، تمامی این تلاش‌ها عمدتا بر روی راهکارهای استخراجی 
\footnote{\lr{extractive}}
متمرکز بوده‌اند که هدفشان بازیابی اطلاعات مرتبط از منابع از پیش تعریف شده است، به جای استفاده از رویکردهای تولیدی
\footnote{\lr{generative}}
که قادر به تولید پاسخ‌های آگاه از زمینه باشند.
\subsection{مدل 
	\lr{Sina-bert}
}
شاید اولین و برجسته ترین مدل زبانی پزشکی فارسی، 
\lr{Sina-BERT}
\cite{b30}
باشد که شامل آموزش یک مدل
\lr{BERT}
\cite{b31}
با استفاده از یک پیکره خزش شده
\footnote{\lr{crawled}}
همراه با مجموعه‌داده پرسش و پاسخ پزشکی فارسی است که به طور خاص برای کاربردهای مختلف از جمله پاسخ به سوالات پزشکی، تحلیل احساسات پزشکی و بازیابی سوالات پزشکی توسعه یافته‌اند.

\lr{Sina-BERT}
در میان تلاش‌های متمرکز بر زبان فارسی، بیشترین شباهت را به فاز نخست پایان نامه حاضر دارد؛ با این تفاوت که از مدل برت
\footnote{\lr{BERT}}
یک مدل زبانی مبتنی بر رمزگذار
\footnote{\lr{encoder-based}}
به عنوان مدل پایه استفاده می‌کند. این انتخاب تولید پاسخ توسط این مدل را عملا ناممکن می سازد، چرا که برت عمدتا برای درک و استخراج اطلاعات طراحی شده است نه برای تولید پاسخ.


\subsection{
	سیستم پرسش و پاسخ پزشکی دکتر ویسی و همکاران
}
یکی از آثار برجسته در حوزه پردازش زبان طبیعی، سیستم پرسش و پاسخ پزشکی فارسی است که توسط دکتر ویسی و همکارانش 
\cite{b32}
طراحی و توسعه داده شده است. این سیستم به‌طور کلی شامل سه ماژول اصلی است: پردازش پرسش، بازیابی سند و استخراج پاسخ. ماژول پردازش پرسش وظیفه تحلیل و اصلاح پرسش‌های کاربران را برعهده دارد تا پرسش‌ها به شکل بهینه برای مراحل بعدی آماده شوند. سپس، ماژول بازیابی سند با استفاده از الگوریتم‌های پیشرفته، اسناد پزشکی مرتبط را از میان داده‌های از پیش تعیین‌شده پیدا می‌کند. در نهایت، ماژول استخراج پاسخ با شناسایی دقیق اطلاعات موجود در اسناد بازیابی‌شده، مناسب‌ترین پاسخ‌ها را استخراج کرده و به کاربران ارائه می‌دهد. این سیستم نه تنها به‌طور مؤثر به پرسش‌های پزشکی پاسخ می‌دهد، بلکه ساختار ماژولار آن امکان بهبود و توسعه در آینده را نیز فراهم می‌سازد.
\subsection{
	پایان نامه کارشناسی ارشد خانم لیلا دارابی
}
مشابه به این دو اثر، پیشین لیلا دارابی در پایان نامه ارشد خود
\cite{b33}
از مدل‌هایی مانند 
\lr{Pars-BERT}
\cite{b34}
برای بازیابی پاسخ‌های مرتبط استفاده کرده است. رویکرد او شامل یافتن سوالات مشابه برای مدیریت پرسش‌های تکراری و به کارگیری استراتژی‌های ارزیابی دقیق و سهل‌گیرانه برای پاسخ‌های دقیق یا تقریبی می‌شود. علاوه بر این، روش‌های طبقه‌بندی و شناسایی موجودیت‌های نامدار
\footnote{\lr{named entity recognition}}
برای بهبود ارتباط پاسخ‌ها از طریق دسته‌بندی سوالات و شناسایی موجودیت‌های پزشکی مانند نام داروها و بیماری‌ها به کار گرفته می‌شوند.

\section{بهبود قابلیت دلیل آوری در حوزه پزشکی}
\subsection{
مدل 
\lr{MedSSS}
}
یکی از تلاش‌های برجسته در این حوزه، مدل زبانی
\lr{MedSSS}
است.
\cite{b35}
هدف اصلی این چارچوب، ارتقای توانایی استدلال مدل‌های پزشکی از طریق دقت‌بخشی و ریزسازی مراحل میانی استدلال بین پرسش و پاسخ نهایی است.
همانطوری که در تصویر
\ref{fig9}
برای دستیابی به این هدف، پژوهشگران از الگوریتم جست‌وجوی درختی مونت‌کارلو
\footnote{\lr{monte carlo tree search}}
\cite{b36}
استفاده کردند. این الگوریتم بر روی مجموعه‌داده‌هایی از پرسش‌های چندگزینه‌ای پزشکی به‌کار گرفته شد تا مسیرهای استدلالی ساختارمند و مرحله‌به‌مرحله تولید شود؛ مسیرهایی که نشان می‌دهند مدل چگونه از پرسش به پاسخ درست می‌رسد.
بر اساس این رویکرد، نویسندگان به صورت مصنوعی سه مجموعه‌داده مجزا ساختند که هر یک در مرحله‌ای خاص از آموزش مدل نقش دارد:

\begin{enumerate}
    \item مجموعه‌دادهٔ تنظیم دقیق نظارت‌شده : برای آموزش مدل سیاستی
    \footnote{\lr{policy model}}
    از طریق نمونه‌های استدلال باکیفیت.
    \item مجموعه‌دادهٔ پاسخ‌های ترجیح‌داده‌شده و ردشده: برای آموزش مبتنی بر بهینه‌سازی مستقیم ترجیحات
    \footnote{\lr{direct preference optimization}}
    تا مدل بتواند میان پاسخ‌های بهتر و ضعیف‌تر تمایز قائل شود.
    \item مجموعه‌داده برچسب‌های نرم دوسویه: جهت تنظیم دقیق مدل پاداش فرآیند 
    \footnote{\lr{process reward model}}
    که به‌جای تمرکز صرف بر پاسخ نهایی، کیفیت فرآیند استدلال مدل را ارزیابی می‌کند.
\end{enumerate}
در نهایت، مدل سیاستی آموزش‌دیده به‌عنوان موتور اصلی استدلال در فرآیند تولید پاسخ عمل می‌کند، در حالی که مدل پاداش فرآیند آموزش‌دیده نقش راهنما و ارزیاب را در هنگام تولید ایفا می‌نماید. این مدل دوم کمک می‌کند تا فرآیند استدلال مدل به‌صورت پیوسته اصلاح شده و از نظر منطق، انسجام و درستی پزشکی ارزیابی گردد.

 \begin{figure}[ht]
 	\centerline{\includegraphics[width=0.9\textwidth]{fig9}}
 	\caption{
 		بلوک دیاگرام مدل
 		\lr{medsss}
 	}
 	\label{fig9}
 \end{figure}
 
\subsection{
مدل 
\lr{MedReason}
}

یکی دیگر از دستاوردهای مهم در زمینهٔ توسعهٔ مدل‌های زبانی استدلال‌محور در حوزهٔ پزشکی، مدل زبانی
\lr{MedReason}
است.
\cite{b37}
در این پژوهش، نویسندگان از یک گراف دانش ساختاریافته پزشکی
\footnote{\lr{medical knowledge graph}}
بهره گرفتند تا جفت‌های متداول پرسش و پاسخ را به مسیرهای استدلالی دقیق و گام‌به‌گام تبدیل کنند. هر مسیر استدلالی، زنجیره‌ای منطقی از گام‌های مرتبط را نشان می‌داد که یک پرسش بالینی را به پاسخ صحیح آن متصل می‌کرد و این ارتباط بر پایهٔ روابط دانش پزشکی مانند علائم، تشخیص‌ها، درمان‌ها و سازوکارهای فیزیولوژیکی بنا شده بود.

پژوهشگران با ساخت چنین مجموعه‌داده‌ای غنی‌شده از استدلال، توانستند یک مدل زبانی پایه را بر اساس این نمونه‌های ساختاریافته تنظیم دقیق کنند. این رویکرد سبب شد تا توانایی مدل در انجام وظایف پیچیده و استدلال‌محور در حوزهٔ پزشکی به‌طور قابل‌توجهی بهبود یابد. نتایج حاصل نشان داد که نظارت مبتنی بر استدلالِ استخراج‌شده از گراف‌های دانش، می‌تواند نقش مؤثری در ارتقای دقت و قابلیت تحلیل مدل‌های زبانی پزشکی ایفا کند.

یافته‌های حاصل از پژوهش
\lr{MedReason}
همچنین بر اهمیت نمایش‌های ساختاریافتهٔ استدلال در بهبود تفسیرپذیری
\footnote{\lr{interpretability}}
و عمق تحلیلی مدل‌های زبانی پزشکی تأکید می‌کنند. این چارچوب نشان می‌دهد که ترکیب دانش ساختاریافته با فرآیند یادگیری زبانی، می‌تواند پلی میان درک داده‌محور و استدلال مبتنی بر دانش در سامانه‌های هوش مصنوعی پزشکی ایجاد کند.


\subsection{
مدل 
\lr{HuatuoGPT-o1}
}
یکی از پیشرفت‌های مهم دیگر در توسعه مدل‌های زبانی استدلال‌محور پزشکی، چارچوبی با نام
\lr{HuatuoGPT-o1}
است.
\cite{b38}
در این پژوهش، نویسندگان یک چارچوب استدلال با هدایتِ اعتبارسنجی
\footnote{\lr{verification guided reasoning framework}}
را معرفی کردند که هدف آن بهبود انسجام منطقی و دقت مسیرهای استدلالی تولیدشده توسط مدل است. 

در این رویکرد، یک مدل اعتبارسنج
\footnote{\lr{verifier model}}
به‌عنوان جز کنترلی و ارزیاب به‌کار گرفته شد تا در حین فرآیند تولید استدلال، عملکرد مدل سیاستی را ارزیابی و هدایت کند. این مکانیزم اطمینان حاصل می‌کرد که هر مسیر استدلالی تولیدشده با واقعیت‌های علمی و اصول پذیرفته‌شدهٔ پزشکی سازگار باشد. با استفاده از فرآیند فیلترسازی و پالایش مسیرهای استدلال از طریق این مدل اعتبارسنج، پژوهشگران موفق به تولید یک مجموعه‌دادهٔ باکیفیت متشکل از دنباله‌های استدلالی تأییدشده شدند.

در گام بعد، نویسندگان از ترکیب دو رویکرد آموزش، شامل تنظیم دقیق نظارت‌شده  و یادگیری تقویتی ، برای آموزش مدل زبانی پایه با استفاده از داده‌های اعتبارسنجی‌شده بهره بردند. این رویکرد دوگانه باعث شد مدل نه‌تنها رفتارهای استدلالی صحیح را تقلید کند، بلکه اصول استدلال منطقی را از طریق بهینه‌سازی مبتنی بر پاداش درونی‌سازی نماید. 
نتایج حاصل از این پژوهش نشان داد که مدل
\lr{HuatuoGPT-o1}
در طیف وسیعی از وظایف پزشکی، از جمله پاسخ‌گویی به پرسش‌های بالینی و استدلال تشخیصی، بهبود چشمگیری در دقت و قابلیت اعتماد از خود نشان می‌دهد. این دستاورد اهمیت چارچوب‌های یادگیری هدایت‌شده با اعتبارسنج را در ارتقای مدل‌های زبانی استدلالی در حوزهٔ پزشکی برجسته می‌سازد و مسیر توسعه سامانه‌های هوش مصنوعی با استدلال قابل اعتماد را هموار می‌کند.

\section{بهبود قابلیت دلیل آوری در حوزه های دیگر}

\subsection{
مدل دیپ سیک
}
یکی از تاثیرگذارترین پژوهش‌های اخیر در حوزه گسترده استدلال در هوش مصنوعی، مدل
\lr{DeepSeek-R}
است.
\cite{b39}
این مدل بر پایه نسخه پایه
\lr{DeepSeek-V3-Base}
توسعه یافته و با هدف ارتقای صریح قابلیت‌های استدلالی، چارچوبی مبتنی بر یادگیری تقویتی را به‌کار می‌گیرد. در این چارچوب، نویسندگان از الگوریتم ‫ﺑﻬﯿﻨﻪ‬ ‫ﺳﺎزی‬‫ﺳﯿﺎﺳﺖ‬ ‫ﺑﺮ‬ ‫ﭘﺎﯾﻪ‬ ‫ﭘﺎداش‬ ‫ﮔﺮوﻫﯽ‬
\footnote{\lr{group reward policy optimization}}
استفاده کردند تا فرآیند یادگیری تقویتی را به‌گونه‌ای هدایت کنند که عملکرد استدلالی مدل به‌صورت هدفمند بهبود یابد.

در این رویکرد، تابع پاداش به‌طور ویژه طراحی شد تا کیفیت استدلال مدل را ارزیابی کرده و آن را به حداکثر برساند. نتایج نشان داد که مدل DeepSeek-R از طریق این الگوی آموزشی، پیشرفت چشمگیری در منطق استدلالی و دقت حل مسئله در مجموعه‌ای از معیارهای استاندارد 
\footnote{\lr{benchmarks}}
به‌دست آورده است. با این حال، استفاده از یادگیری تقویتی بدون کنترل کامل، پیامدهایی جانبی نیز به همراه داشت؛ از جمله کاهش روانی زبان، افت انسجام جمله‌ای، و افزایش بروز پدیده اختلاط زبانی
\footnote{\lr{language mixing}}
در خروجی مدل.

برای رفع این چالش‌ها، پژوهشگران مرحله‌ای تکمیلی به فرآیند آموزش افزودند. در این مرحله، مقدار اندکی داده نظارت‌شده اولیه
\footnote{\lr{cold-start supervised data}}
مورد استفاده قرار گرفت و یک زنجیره آموزشی چندمرحله‌ای
\footnote{\lr{multi-stage training pipeline}}
طراحی شد. این فاز تنظیم دقیق کمک کرد تا ضمن حفظ توانمندی‌های استدلالی کسب‌شده از یادگیری تقویتی، روانی و خوانایی زبان طبیعی نیز بازگردانده شود.

در نتیجه، مدل
\lr{DeepSeek-R}
به‌عنوان گامی اساسی در مسیر توسعهٔ هوش مصنوعی استدلال‌محور مطرح شد؛ مدلی که نشان می‌دهد یادگیری تقویتی می‌تواند به‌طور قابل توجهی توانایی استدلال را ارتقا دهد، مشروط بر آنکه با تنظیم دقیق و نظارت زبانی هدفمند ترکیب شود تا تعادل میان کیفیت زبانی و عمق استدلالی حفظ گردد.

\subsection{
چهارچوب بهینه سازی ترجیحات فکری
}


یکی از دستاوردهای قابل توجه در زمینه بهبود توانایی استدلال در مدل‌های زبانی، روش بهینه سازی ترجیحات فکری
\footnote{\lr{thought preference optimization}}
است.
\cite{b40}
در این پژوهش، نویسندگان چارچوبی مبتنی بر ترجیحات را برای ارتقای کیفیت استدلال در مدل‌های زبانی پیشنهاد کردند. 

همانطور که در تصویر
\ref{fig10}
میبینید در این رویکرد، هنگامی که یک پرسش به مدل ارائه می‌شود، ابتدا مدل چندین مسیر استدلالی متفاوت را به‌عنوان پاسخ‌های بالقوه تولید می‌کند. سپس این مسیرهای استدلالی توسط یک مدل داور
\footnote{\lr{judge model}}
مورد ارزیابی قرار می‌گیرند. مدل داور با بررسی صحت منطقی، انسجام و کیفیت استدلال، بهترین و ضعیف‌ترین نمونه‌ها را از میان خروجی‌ها شناسایی می‌کند. 

در گام بعد، جفت‌های انتخاب‌شده از پاسخ‌های «بهتر» و «ضعیف‌تر» برای آموزش مدل پایه با استفاده از روش ‫ﺑﻬﯿﻨﻪ‬ ‫ﺳﺎزی‬‫ ﻣﺴﺘﻘﯿﻢ‬ ‫ﺗﺮﺟﯿﺤﺎت‬
\footnote{\lr{direct preference optimization}}
به‌کار گرفته می‌شوند. این فرآیند باعث می‌شود مدل به‌صورت تدریجی مسیرهای استدلالی باکیفیت‌تر را ترجیح دهد و یاد بگیرد که استدلال‌هایی منطقی‌تر، پیوسته‌تر و نزدیک‌تر به شیوهٔ تفکر انسانی تولید کند. 

نتایج این پژوهش نشان داد که به‌کارگیری چارچوب
\lr{TPO}
موجب بهبود چشمگیری در کیفیت استدلال مدل‌های زبانی می‌شود. این یافته بیانگر آن است که ارتقای توانایی استدلالی مدل‌ها تنها از طریق افزایش مقیاس یا داده‌های آموزشی نظارت‌شده حاصل نمی‌شود، بلکه می‌توان با بهره‌گیری از سازوکارهای یادگیری مبتنی بر ترجیح و بازخورد ارزیابانه، به بهبودی مؤثرتر و پایدارتر در فرآیند استدلال مدل دست یافت.



 \begin{figure}[ht]
 	\centerline{\includegraphics[width=0.9\textwidth]{fig10}}
 	\caption{
 		بلوک دیاگرام 
 		\lr{thought preference optimization}
 	}
 	\label{fig10}
 \end{figure}

\subsection{
آموزش استدلال مدل های بزرگ به مدل های کوچک
}
یکی از پژوهش‌های مرتبط در زمینه انتقال توانایی استدلال میان مدل‌های زبانی، توسط آقای هو و همکاران انجام شده است.
\cite{b41}
در این پژوهش، نویسندگان به بررسی چگونگی انتقال قابلیت‌های استدلالی از مدل‌های زبانی بزرگ به مدل‌های کوچک‌تر پرداختند. ایدهٔ اصلی این رویکرد بر آن استوار است که مدل‌های کوچک‌تر می‌توانند از داده‌های تولیدشده توسط مدل‌های بزرگ‌تر، که از قدرت استدلالی بالاتری برخوردارند، برای بهبود عملکرد خود بهره ببرند.

همانطور که در تصویر
\ref{fig11}
در این روش، ابتدا یک مدل زبانی بزرگ با عملکرد استدلالی قوی‌تر به تولید مسیرهای استدلالی 
\footnote{\lr{reasoning trajectories}}
و جفت‌های پرسش و پاسخ می‌پردازد. این خروجی‌ها به‌عنوان داده‌های آموزشی باکیفیت و مبتنی بر استدلال، برای تنظیم دقیق مدل کوچک‌تر مورد استفاده قرار می‌گیرند. بدین ترتیب، مدل کوچک‌تر از این طریق، الگوهای حل مسئله و استراتژی‌های استدلالی را از مدل بزرگ‌تر فرا می‌گیرد.

نتایج نشان داد که مدل کوچک‌تر پس از این آموزش هدفمند، توانست عملکردی رقابتی در وظایف استدلالی از خود نشان دهد؛ در حالی‌که هزینهٔ محاسباتی آن به‌طور قابل‌توجهی کمتر از مدل بزرگ‌تر بود. این پژوهش اهمیت استفاده از داده‌های مصنوعی مبتنی بر استدلال و یادگیری انتقالی هدفمند را در بهبود بازده و کارایی مدل‌های زبانی کوچک‌تر برجسته می‌کند. به‌عبارت دیگر، توانایی استدلال را می‌توان به‌صورت مؤثر میان مدل‌هایی با مقیاس‌های متفاوت منتقل کرد، مشروط بر آنکه فرآیند تنظیم دقیق بر اساس داده‌های تولیدشده از مدل‌های استدلالی پیشرفته انجام گیرد.

 \begin{figure}[ht]
 	\centerline{\includegraphics[width=0.6\textwidth]{fig11}}
 	\caption{
 		بلوک دیاگرام آموزش دلیل آوری توسط مدل بزرگتر به مدل کوچکتر
 	}
 	\label{fig11}
 \end{figure}

