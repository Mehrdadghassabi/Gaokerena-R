% !TeX root=../main.tex
\chapter{
	معرفی مدل زبانی گائوکرنا-\lr{R}
}
\section{
مقدمه
}
در این بخش، ما به معرفی
\lr{gaokerena-R}
می‌پردازیم. در این نسخه، دو روش نوین ارائه می‌شود که با استفاده از مقدار کمی داده می‌توانند توانایی‌های استدلالی مدل پایه را به‌صورت قابل‌توجهی بهبود بخشند. نتایج نشان می‌دهد که این رویکرد جدید عملکردی بهتر از
\lr{gaokerena-V}
دارد؛ مدلی که با حجم زیادی از داده‌ها آموزش دیده است. در ادامه، این فرضیه مطرح می‌شود که ارتقای مهارت‌های استدلالی در مدل‌های زبانی کوچک و کم‌منبع حوزه پزشکی، تاثیرگذارتر و سودمندتر از صرفا افزایش مقیاس داده‌ها است.
\section{
‫ﻣﺪل‬‫ﭘﺎﯾﻪ‬
}
به همان دلیلی که برای مدل 
\lr{gaokerena-V}
، مدل 
\lr{aya-expanse-8b}
\cite{b57}
را به‌عنوان مدل پایه
\footnote{\lr{baseline model}}
انتخاب کردیم، برای مدل
\lr{gaokerena-R}
نیز از همان مدل پایه استفاده می‌کنیم. هدف از این انتخاب، حفظ یک مبنای یکسان برای ارزیابی دقیق و منصفانه میان دو رویکرد است. دلیل دیگر این تصمیم، امکان مقایسه‌ی عادلانه میان آموزش مدل بر حجم عظیمی از داده‌ها و روش پیشنهادی ما برای بهبود مهارت‌های استدلالی است. با این کار، می‌توان به‌روشنی تاثیر واقعی افزایش توانایی استدلال در برابر صرفا گسترش داده‌های آموزشی را بررسی کرد و نشان داد که چگونه تقویت استدلال می‌تواند حتی در شرایط داده‌های محدود، موجب ارتقای عملکرد مدل شود.

به دلیل محدودیت‌های سخت‌افزاری و سرعت بالای چارچوب اول، مدل پایه
\lr{aya-expanse-8b}
را با چارچوب اول برای
\lr{95}
درصد داده‌ها و چارچوب دوم برای
\lr{5}
درصد باقی‌مانده آموزش دادیم. این رویکرد، آموزش کارآمد با بهینه‌سازی ترجیح مستقیم را ممکن ساخت و شامل
\lr{11000}
جفت پاسخ ترجیحی-ردشده با حدود
\lr{2}
میلیون توکن ترجیحی و
\lr{2.5}
میلیون توکن ردشده بود. این ترکیب، زمان آموزش را بهینه کرد و با بهره‌گیری از بازخورد دقیق چارچوب دوم، مهارت‌های استدلالی مدل را در مسائل پزشکی تقویت نمود.
\section{
متد های معرفی شده
}
همان‌طور که پیش‌تر اشاره شد، برای تقویت مهارت‌های استدلالی در حوزه پزشکی، دو روش نوین معرفی شده‌اند. روش نخست سریع‌تر از روش دوم عمل می‌کند، اما روش دوم داده‌های باکیفیت‌تری برای آموزش تولید می‌نماید. در ادامه، به توضیح جزئیات این دو روش می‌پردازیم.
\subsection{
روش نخست
}
روش نخست، که در شکل
\ref{fig14}
و الگوریتم
\ref{alg:m1}
نمایش داده شده است، از یک مدل معلم (در این پژوهش از مدل زبانی
\lr{DeepSeek-R}
استفاده شده است) بهره می‌گیرد. این مدل معلم، خود یک مدل زبانی با قابلیت استدلال پیشرفته است که وظیفه دارد خطاهای استدلالی مدل دانش‌آموز را در پاسخ به پرسش‌های چندگزینه‌ای حوزه پزشکی شناسایی و اصلاح کند. در این فرآیند، اگر مدل دانش‌آموز گزینه‌ی صحیح را انتخاب کند، بدون نیاز به مداخله‌ی بیشتر، به سؤال بعدی در مجموعه‌داده منتقل می‌شویم. اما در صورتی که مدل دانش‌آموز پاسخ نادرست دهد، مدل معلم با در نظر گرفتن پاسخ درست، یک توضیح گام‌به‌گام و دقیق در قالب زنجیره استدلال
\footnote{\lr{chain-of-thought}}
تولید می‌کند که منطق، شواهد و روند تفکر پشت پاسخ صحیح را آشکار می‌سازد. این توضیحات نه‌تنها اشتباه مدل دانش‌آموز را مشخص می‌کنند، بلکه نحوه‌ی استدلال صحیح در مسائل پزشکی را نیز آموزش می‌دهند. در این سازوکار، خروجی مدل معلم به‌عنوان پاسخ برگزیده
\footnote{\lr{preferred answer}}
تلقی می‌شود و پاسخ اولیه‌ی مدل دانش‌آموز به‌عنوان پاسخ مردود
\footnote{\lr{rejected answer}}
برای فرآیند ‫ﺑﻬﯿﻨﻪ‬ ‫ﺳﺎزی‬ ‫ﻣﺴﺘﻘﯿﻢ‬ ‫ﺗﺮﺟﯿﺤﺎت‬
\footnote{\lr{direct preference optimization}}
\cite{b19}
مورد استفاده قرار می‌گیرد. این چارچوب آموزشی به مدل دانش‌آموز امکان می‌دهد تا از طریق بازخورد مستقیم مدل معلم، به شکلی هدفمند مهارت‌های استدلالی خود را تقویت کرده و درک عمیق‌تری از منطق پزشکی در پرسش‌های چندگزینه‌ای به دست آورد.
\begin{figure}[ht]
	\centerline{\includegraphics[width=0.7\textwidth]{fig14}}
	\caption{
	  بلوک دیاگرام شیوه نخست
	}
	\label{fig14}
\end{figure}

\begin{algorithm}[ht]
	\onehalfspacing
	\caption{
		شیوه دوم پیشنهاد شده برای بهبود دلیل آوری
	} \label{alg:m1}
	\begin{algorithmic}[1]
		\REQUIRE پرسش و پاسخ های چند گزینه پزشکی	
		\\
		\FOR{به ازای تمامی پرسش ها}
		\STATE یکی از پرسش های پزشکی را از مدل دانشجو بپرس
		\IF{اگر پاسخ دانشجو درست بود}
		\STATE این پرسش را کنار بگذار و به سراغ پرسش بعدی برو
		\ENDIF
		\STATE پاسخ نادرست دانشجو را ذخیره کن
		\STATE  پاسخ نادرست دانشجو را به همراه کلید پاسخ معلم بده و از او بخواه که استدلال نادرست دانشجو را اصلاح کند
		\STATE پاسخ معلم را به عنوان پاسخ صحیح ذخیره کن
		\STATE پاسخ درست و نادرست را به عنوان جفت ذخیره کن
		\IF{در صورت جمع شدن تعداد کافی جفت پاسخ درست و نادرست}
		\STATE مدل دانشجو را با استفاده از بهینه سازی مستقیم ترجیحات تمرین بده
		\ENDIF
		\ENDFOR
		

		
	\end{algorithmic}
\end{algorithm}

\subsection{
روش دوم
}
روش دوم، که در شکل
\ref{fig15}
و الگوریتم 
\ref{alg:m1}
نشان داده شده است، از مدل معلم استفاده می‌کند تا بازخورد دقیق‌تری ارائه دهد. این روش با شناسایی خطاهای خاص در پاسخ مدل دانش‌آموز به یک پرسش چندگزینه‌ای عمل می‌کند. پس از دریافت این بازخورد، مدل دانش‌آموز تشویق می‌شود تا پاسخ خود را دقیقا از نقطه‌ای که خطا رخ داده است، اصلاح کند. از طریق این فرآیند تکراری، مدل دانش‌آموز به‌تدریج مسیر استدلالی
\footnote{\lr{reasoning trajectories}}
\cite{b79}
خود را بهبود می‌بخشد و به پاسخ صحیح همگرا می‌شود. این بازخورد سازنده به مدل دانش‌آموز امکان می‌دهد تا استقلال استدلالی خود را تقویت کند، زیرا یاد می‌گیرد خطاهای خود را به‌جای تقلید صرف از پاسخ‌های مدل معلم، اصلاح نماید. در این چارچوب، پاسخ نهایی تولیدشده توسط مدل دانش‌آموز به‌عنوان پاسخ ترجیحی در نظر گرفته می‌شود، در حالی که تلاش اولیه آن به‌عنوان پاسخ ردشده برای آموزش ‫ﺑﻬﯿﻨﻪ‬ ‫ﺳﺎزی‬ ‫ﻣﺴﺘﻘﯿﻢ‬ ‫ﺗﺮﺟﯿﺤﺎت‬ 
استفاده می‌شود. اگرچه این چارچوب دوم به دلیل فرآیند بازخورد تکراری زمان‌برتر است، اما آموزش ‫ﺑﻬﯿﻨﻪ‬ ‫ﺳﺎزی‬ ‫ﻣﺴﺘﻘﯿﻢ‬ ‫ﺗﺮﺟﯿﺤﺎت‬
را ساده‌تر می‌کند، زیرا هر دو پاسخ ردشده و ترجیحی به‌طور کامل توسط خود مدل دانش‌آموز و به‌صورت توالی‌هایی از توکن‌های خودش تولید می‌شوند. این رویکرد نه‌تنها به مدل دانش‌آموز کمک می‌کند تا مهارت‌های استدلالی خود را به‌صورت مستقل توسعه دهد، بلکه با تولید داده‌های آموزشی باکیفیت‌تر، کارایی فرآیند یادگیری را نیز افزایش می‌دهد.

\begin{figure}[ht]
	\centerline{\includegraphics[width=0.7\textwidth]{fig15}}
	\caption{
	  بلوک دیاگرام شیوه دوم
	}
	\label{fig15}
\end{figure}

\begin{algorithm}[ht]
	\onehalfspacing
	\caption{
		شیوه دوم پیشنهاد شده برای بهبود دلیل آوری
	} \label{alg:m1}
	\begin{algorithmic}[1]
		\REQUIRE پرسش و پاسخ های چند گزینه پزشکی	
		\\
		\FOR{به ازای تمامی پرسش ها}
		\STATE یکی از پرسش های پزشکی را از مدل دانشجو بپرس
		\IF{اگر پاسخ دانشجو درست بود}
		\STATE این پرسش را کنار بگذار و به سراغ پرسش بعدی برو
		\ENDIF
		\STATE پاسخ نادرست دانشجو را ذخیره کن
		\WHILE{تا زمانی که دانشجو پاسخ نادرست را نیافته است}
		\STATE پاسخ نادرست دانشجو را به معلم بده و از او بخواه که استدلال نادرست را گزارش کند
		\STATE گزارش معلم را به دانشجو بده و از او بخواه به پرسش دوباره پاسخ دهد
		\ENDWHILE
		\STATE پاسخ درست دانشجو را ذخیره کن
		\STATE پاسخ درست و نادرست را به عنوان جفت ذخیره کن
		\IF{در صورت جمع شدن تعداد کافی جفت پاسخ درست و نادرست}
		\STATE مدل دانشجو را با استفاده از بهینه سازی مستقیم ترجیحات تمرین بده
		\ENDIF
		\ENDFOR
		

		
	\end{algorithmic}
\end{algorithm}


\section{
ردپای کربن
}
ردپای کربنی فرآیند تمرین مدل
\lr{gaokerena-R}
بر اساس پیکربندی سخت‌افزاری و مدت‌زمان کل اجرا برآورد شده است. در این فرآیند، با بهره‌گیری از مجموعه‌داده‌ی ترجمه‌شده‌ی ماشینی
\lr{MedMCQA}
\cite{b51}
و به‌کارگیری دو روش پیشنهادی همراه با بهینه‌سازی مستقیم ترجیحات مدل مورد نظر به‌مدت تقریبی یک ساعت بر روی یک کارت گرافیک
\lr{NVIDIA H100 PCIe}
با حافظه‌ی
\lr{80}
گیگابایت آموزش داده شد. در طول این فرآیند، حدود
\lr{43}
گیگابایت از حافظه‌ی گرافیکی
\footnote{\lr{VRAM}}
مورد استفاده قرار گرفت. نمودار تغییرات تابع خطا در طول آموزش در شکل
\ref{fig16}
نمایش داده شده است.

با در نظر گرفتن میانگین توان مصرفی حدود
\lr{350}
وات برای هر
\lr{GPU}
،میزان کل انرژی مصرفی در این فرآیند تقریبا
\lr{0.35}
کیلووات‌ساعت برآورد می‌شود. با توجه به شدت متوسط کربن شبکه‌ی برق کانادا، جایی که سرور ما در آن قرار داشت (هشتاد و شش گرم دی‌اکسید کربن معادل برای هر کیلووات‌ساعت)، میزان انتشار کربن حاصل از این فرآیند در حدود سی گرم دی‌اکسید کربن تخمین زده می‌شود.

در مقایسه با مدل قبلی ما،
\lr{gaokerena-V}،
که انتشار تقریبی
\lr{2.66}
کیلوگرم دی‌اکسید کربن داشت، این مقدار کاهش چشمگیری در تاثیرات زیست‌محیطی را نشان می‌دهد. این نتیجه بیانگر آن است که روش جدید ما نه‌تنها از نظر کارایی و بهینه‌سازی استدلال عملکرد بهتری دارد، بلکه از منظر پایداری زیست‌محیطی نیز بسیار کارآمدتر و سازگارتر با محیط زیست عمل می‌کند.
\cite{b65}

\begin{figure}[ht]
	\centerline{\includegraphics[width=0.7\textwidth]{fig16}}
	\caption{
	  ‫ﻧﻤﻮدار‬ ‫ﮐﺎﻫﺶ‬ ‫ﺧﻄﺎ‬ ﺑﻬﯿﻨﻪ‬ ‫ﺳﺎزی‬ ‫ﻣﺴﺘﻘﯿﻢ‬ ‫ﺗﺮﺟﯿﺤﺎت‬
	}
	\label{fig16}
\end{figure}


\section{
نتایج
}
در این بخش، مدل تازه توسعه‌یافته
\lr{gaokerena-R}
را با مدل پیشین ،
\lr{gaokerena-V}
، مقایسه می‌کنیم. در حالی که
\lr{gaokerena-V}
روی مجموعه داده‌های پزشکی بزرگی آموزش دیده و دانش پزشکی قوی و قابلیت‌های بازیابی خوبی را نشان می‌دهد،
\lr{gaokerena-R}
به‌طور خاص برای تقویت استدلال پزشکی
\footnote{\lr{medical reasoning}}
طراحی شده است. به دلیل خط‌مشی آموزشی متمرکز بر استدلال،
\lr{gaokerena-R}
روی مجموعه داده‌ای به‌مراتب کوچک‌تر آموزش دیده که منجر به پوشش کمی محدودتر دانش پزشکی عمومی شده است. بااین‌حال، مدل
\lr{gaokerena-R}
توانسته شایستگی استدلالی عمیق‌تری نشان داده و در وظایفی که نیاز به استنتاج چندمرحله‌ای و انسجام منطقی دارند، عملکرد بهتری داشته باشد. در ارزیابی نهایی، عملکرد
\lr{gaokerena-V}
با استفاده از درخواست‌های
\footnote{\lr{prompt}}
مستقیم با عملکرد
\lr{gaokerena-R}
هنگام استفاده از درخواست‌های زنجیره‌ای فکری
\footnote{\lr{chain of thought}}
مقایسه میشود.

نتایج نشان می‌دهد که 
\lr{gaokerena-R}
، با وجود مقیاس کوچک‌تر و داده‌های آموزشی محدود، از طریق هدایت استدلال ساختاریافته، عملکرد برتری را نشان داده و این موضوع اثربخشی بهینه‌سازی متمرکز بر استدلال را در مقایسه با افزایش صرف مقیاس داده‌ها نشان می‌دهد.

\subsection{
سنجش استدلال پزشکی
}
برای ارزیابی قابلیت‌های استدلال پزشکی مدل‌ها، از آن‌ها خواستیم تا مسیرهای استدلال زنجیره‌ای فکری را با تنظیم دمای
\lr{1.0}
تولید کنند. از آنجا که همه مدل‌ها ممکن است پاسخ‌های متفاوتی برای یک پرسش یکسان ارائه دهند، عملکرد آن‌ها را با استفاده از دو معیار دقت و 
\lr{pass@k}
\cite{b80}
روی مجموعه داده‌های ترجمه فارسی 
\lr{MMLU}
\cite{b11}
و کنکور علوم پایه پزشکی شهریور
\lr{1401}
ارزیابی شده است.
\subsubsection{
دقت
}
معیار اول، دقت برای هر پرسش در مجموعه داده‌ها است. برای هر پرسش، پنج نمونه مستقل تولید شد و مکانیزم رای‌گیری اکثریت اعمال گردید: اگر سه یا بیشتر از پنج پاسخ تولیدشده گزینه یکسانی را انتخاب کردند، آن گزینه به‌عنوان پیش‌بینی نهایی انتخاب شد؛ در غیر این صورت، پرسش بدون پاسخ باقی ماند تا عدم قطعیت مدل را نشان دهد. این چارچوب، برآورد قوی‌ای از سازگاری استدلالی در مسیرهای مختلف ارائه می‌دهد. نتایج در جدول 
\ref{tab:med_reasoning_capabillities_WNM_comparison}
(بدون نمره منفی) و جدول
\ref{tab:med_reasoning_capabillities_NM_comparison}
(با نمره منفی) ارائه شده‌اند، جایی که در تنظیم نمره منفی، هر سؤال پاسخ‌داده‌شده به‌صورت نادرست، امتیاز 
\lr{-0.33}
دریافت می‌کند.

	\begin{table}[ht]
		\centering
		\begin{tabular}{|l|c|c|c|}  
			\hline
			\textbf{} & \textbf{gao} & \textbf{gao} & \textbf{aya-} \\ 
			& \textbf{kerena-R} &  \textbf{kerena-V} & \textbf{\lr{expanse-8b}} \\
			&   & &(baseline)  \\ \hline
			MMLU- &  &  &  \\ 
			anatomy(fa)  & \textbf{\lr{42.22}} & \lr{39.25}  & \lr{40.74} \\ \hline
			MMLU- &    &  &  \\
			medical-genetics(fa) & \textbf{\lr{50.0}}  & \lr{41.0}  & \lr{45.0} \\ \hline
			MMLU- &  &    &  \\
			college-medicine(fa) & \lr{47.97}  & \lr{37.57}  &\textbf{\lr{48.55}}  \\ \hline
			MMLU- &    &  &  \\
			clinical-knowledge(fa)& \textbf{\lr{55.84}} & \lr{46.79}  & \lr{54.71}  \\ \hline
			MMLU- &  &  &  \\
			professional-& \textbf{\lr{44.85}} & \lr{37.13} & \lr{43.75} \\
                        medicine(fa)& &  &  \\ \hline
			MMLU- &  &  &  \\
			college-biology(fa)& \textbf{\lr{48.61}} & \lr{36.80} & \lr{43.75} \\ \hline
			MMLU(avg) & \textbf{\lr{48.76}} & \lr{40.40} & \lr{47.10} \\ \hline
			\lr{IBMSEE Sept2023} & \textbf{\lr{38.69}}  & \lr{29.76} & \lr{35.71}  \\ \hline
			Number of&  &  &  \\
			parameters & \lr{8b} & \lr{8b} & \lr{8b} \\ \hline
			inference time & $\approx 5 \times 35s$ & $\approx 5 \times 35s$ & $\approx 5 \times 35s$ \\  \hline
		\end{tabular}
		\caption{دقت با درخواست زنجیره‌ افکار بدون نمره منفی}
		\label{tab:med_reasoning_capabillities_WNM_comparison}
	\end{table}

	\begin{table}[ht]
		\centering
		\begin{tabular}{|l|c|c|c|}  
			\hline
			\textbf{} & \textbf{gao} & \textbf{gao} & \textbf{aya-} \\ 
			& \textbf{kerena-R} &  \textbf{kerena-V} & \textbf{\lr{expanse-8b}} \\
			&   & &(baseline)  \\ \hline
			MMLU- &  &  &  \\ 
			anatomy(fa)  & \textbf{\lr{29.13}} & \lr{27.65}  & \lr{24.93}  \\ \hline
			MMLU- &    &  &  \\
			medical-genetics(fa) & \textbf{\lr{40.0}}  & \lr{32.0}  & \lr{33.0}  \\ \hline
			MMLU- &  &    &  \\
			college-medicine(fa) & \textbf{\lr{34.68}}  & \lr{25.24}  & \lr{34.48}  \\ \hline
			MMLU- &    &  &  \\
			clinical-knowledge(fa)& \textbf{\lr{44.65}} & \lr{35.59}  & \lr{42.51}  \\ \hline
			MMLU- &  &  &  \\
			professional-& \textbf{\lr{30.39}} & \lr{25.0} & \textbf{\lr{30.39}}  \\
                        medicine(fa)& &  &  \\ \hline
			MMLU- &  &  &  \\
			college-biology(fa)& \textbf{\lr{36.80}} & \lr{25.0}  & \lr{30.09}  \\ \hline
			MMLU(avg) & \textbf{\lr{36.14}} & \lr{28.57}  & \lr{33.55}  \\ \hline
			\lr{IBMSEE Sept2023} & \textbf{\lr{24.60}}  & \lr{15.87} & \lr{19.84}   \\ \hline
			Number of&  &  &  \\
			parameters & \lr{8b} & \lr{8b} & \lr{8b} \\ \hline
			inference time & $\approx 5 \times 35s$ & $\approx 5 \times 35s$ & $\approx 5 \times 35s$ \\  \hline
		\end{tabular}
		\caption{دقت با درخواست زنجیره‌ افکار با نمره منفی}
		\label{tab:med_reasoning_capabillities_NM_comparison}
	\end{table}
           
           
\subsubsection{
Pass@k
}
معیار
\lr{Pass@k}
که ابتدا توسط براون و همکاران معرفی شد، یک معیار قوی برای ارزیابی مدل‌های زبانی ارائه می‌دهد که برای یک ورودی یکسان، در نمونه‌گیری‌های متعدد، خروجی‌های متفاوتی تولید می‌کنند. این معیار، احتمال اینکه مدل حداقل یک پاسخ درست را در
\lr{k}
تلاش مستقل تولید کند، محاسبه می‌کند و بدین ترتیب ارزیابی جامع‌تری از قابلیت اطمینان استدلال و تنوع نمونه‌ها ارائه می‌دهد. تعریف رسمی این معیار در فرمول 
\ref{fr:passatk}
آمده است، که در آن
\lr{N}
نشان‌دهنده تعداد کل نمونه‌های تولیدشده و
\lr{$C_i$}
نشان‌دهنده تعداد نمونه‌های درست برای مسئله
\lr{i}
است.

\begin{equation}
\text{pass@k} = \frac{1}{\text{\lr{\# of problems}}} \sum_{i=1}^{\text{\lr{\# of problems}}} \left( 1 -  \frac{\binom{N - C_i}{k}}{\binom{N}{k}} \right)
\label{fr:passatk}
\end{equation}

با پیروی از همان تنظیمات آزمایشی که پیش‌تر توضیح داده شد، امتیازهای
\lr{Pass@k}
را با
\lr{k = 1,2,3}
روی دو مجموعه‌داده ترجمه قسمت پزشکی
\lr{MMLU}
و کنکور علوم پایه پزشکی شهریور
\lr{1401}
محاسبه کردیم. ارزیابی شامل سه مدل
گائوکرنا-\lr{R}
،
گائوکرنا-\lr{V}
و
\lr{aya-expanse-8b}
 بود. نتایج مربوط به مجموعه‌داده ترجمه قسمت پزشکی
\lr{MMLU}
در شکل
\ref{fig17}
و نتایج کنکور علوم پایه پزشکی شهریور
\lr{1401}
در شکل
\ref{fig18}
نشان داده شده‌اند.
همان‌طور که در شکل‌های
\ref{fig17}
و
\ref{fig18}
مشاهده می‌شود، مدل
گائوکرنا-\lr{R}
به‌طور مداوم در تقریبا تمام مقادیر
\lr{k}
و دسته‌های ارزیابی، عملکرد برتری از خود نشان داد. این بهبود حاکی از آن است که
گائوکرنا-\lr{R}
از قابلیت‌های استدلالی پایدارتر و منسجم‌تری برخوردار است و حتی با تعداد نمونه‌های محدود، پاسخ‌های درست را با اطمینان بیشتری تولید می‌کند.
در مقابل، مدل
گائوکرنا-\lr{V}
در مقادیر کوچک
\lr{k}
عملکرد نسبتا ضعیفی داشت، اما با افزایش
\lr{k}
نتایج آن بهبود یافت. این الگو نشان می‌دهد که
گائوکرنا-\lr{V}
هنگام تولید مسیرهای استدلالی زنجیره‌ای افکار به‌طور قابل‌توجهی نامطمئن‌تر عمل می‌کند و اغلب در نمونه‌های مختلف، پاسخ‌های متنوع یا ناسازگاری تولید می‌نماید.
بنابراین نتایج، برتری چشمگیر در ثبات و قابلیت اطمینان استدلال را که از طریق رویکرد آموزشی هدفمند و متمرکز بر استدلال در مدل
گائوکرنا-\lr{R}
به‌دست آمده است، به‌خوبی برجسته می‌کنند.

\begin{figure}[ht]
	\centerline{\includegraphics[width=0.9\textwidth]{fig17}}
	\caption{
	  نتایج
	  \lr{Pass@k}
	  روی مجموعه‌داده ترجمه قسمت پزشکی
	  \lr{MMLU}
	}
	\label{fig17}
\end{figure}


\begin{figure}[ht]
	\centerline{\includegraphics[width=0.9\textwidth]{fig18}}
	\caption{
	  نتایج
	  \lr{Pass@k}
	  روی مجموعه‌داده کنکور علوم پایه پزشکی شهریور
         \lr{1401}
	}
	\label{fig18}
\end{figure}

\subsection{
سنجش دانش پزشکی
}
همان‌طور که پیش‌تر اشاره شد، مدل
گائوکرنا-\lr{V}
دارای پایه دانش پزشکی گسترده‌تری نسبت به مدل جدیدتر
گائوکرنا-\lr{R}
است؛ عمدتا به این دلیل که بر روی مجموعه‌داده‌های پزشکی به‌مراتب بزرگ‌تر و متنوع‌تری آموزش دیده است.
این تفاوت به‌ویژه زمانی آشکار می‌شود که هر دو مدل با درخواست‌های مستقیم ارزیابی شوند، نه زمانی که از آن‌ها درخواست زنجیره افکار می‌شود؛ زیرا در حالت دوم، توانایی استدلال مدل نیز بر عملکرد نهایی تاثیر قابل‌توجهی می‌گذارد.
همان‌طور که در جدول
\ref{tab:med_knowledge_comparison}
نشان داده شده، در شرایط درخواست مستقیم،
گائوکرنا-\lr{V}
عملکرد برتری از خود نشان می‌دهد که این امر بیانگر توانایی قوی‌تر آن در به‌خاطرسپردن و بازیابی حقایق پزشکی ناشی از پیش‌آموزش گسترده است.
نکته جالب توجه اینکه عملکرد
گائوکرنا-\lr{R}
و مدل پایه آن
\lr{aya-expanse-8b}
در شرایط درخواست مستقیم تقریبا برابر است. این مشاهدت حاکی از آن است که برتری
گائوکرنا-\lr{R}
در سناریوهای زنجیره افکار، عمدتا ناشی از مهارت‌های استدلالی پیشرفته‌تر آن نسبت به مدل پایه است، نه افزایش قابل‌توجه دانش پزشکی.

	\begin{table}[ht]
		\centering
		\begin{tabular}{|l|c|c|c|}  
			\hline
			\textbf{} & \textbf{gao} & \textbf{gao} & \textbf{aya-} \\ 
			& \textbf{kerena-R} &  \textbf{kerena-V} & \textbf{\lr{expanse-8b}} \\
			&   & &(baseline)  \\ \hline
			MMLU- &  &  &  \\ 
			anatomy(fa)  & \lr{41.48} & \textbf{\lr{48.14}}  & \lr{40.74}  \\ \hline
			MMLU- &    &   &   \\
			medical-genetics(fa) & \lr{49.0}  & \textbf{\lr{53.0}}  &  \lr{49.0} \\ \hline
			MMLU- &  &    &  \\
			college-medicine(fa) & \textbf{\lr{46.24}} & \lr{43.93}  & \lr{44.51}   \\ \hline
			MMLU- &    &  &  \\
			clinical-knowledge(fa) & \lr{52.45} & \textbf{\lr{55.47}}  & \lr{52.07}  \\ \hline
			MMLU- &  &  &  \\
			professional-& \lr{41.91}  & \textbf{\lr{47.05}}  & \lr{45.58}   \\
                        medicine(fa)& &   &   \\ \hline
			MMLU- &  &  &  \\
			college-biology(fa)& \lr{44.44} & \textbf{\lr{47.22}}  &  \lr{45.14} \\ \hline
			MMLU(avg) & \lr{46.28} & \textbf{\lr{49.31}}  & \lr{46.64} \\ \hline
			\lr{IBMSEE Sept2023} & \lr{35.11}  &\textbf{\lr{38.69}} & \lr{34.52}  \\ \hline
			Number of&  &  &  \\
			parameters & \lr{8b} & \lr{8b} & \lr{8b} \\ \hline
			inference time & $\approx10s$ & $\approx 10s$ & $\approx 10s$ \\  \hline
		\end{tabular}
		\caption{دقت با درخواست مستقیم}
		\label{tab:med_knowledge_comparison}
	\end{table}



\subsection{
سنجش پایانی
}
همان‌طور که پیش‌تر بحث شد، مدل
گائوکرنا-\lr{V}
در حالت درخواست مستقیم عملکرد بهتری از خود نشان می‌دهد، در حالی که
گائوکرنا-\lr{R}
زمانی برتر است که از آن درخواست زنجیره افکار شود؛ یعنی از مدل خواسته شود پیش از ارائه پاسخ نهایی، گام‌به‌گام استدلال کند.
یکی از مزایای کلیدی پرامپت کردن با زنجیره افکار – به‌ویژه هنگامی که با نمونه‌برداری چندگانه 
\footnote{\lr{multiple sampling}}
و رای‌گیری اکثریت
\footnote{\lr{majority voting}}
ترکیب شود – این است که به‌طور طبیعی میزان اطمینان مدل را نشان می‌دهد. اگر پاسخ‌های تولیدشده در نمونه‌های مختلف به یک گزینه همگرا شوند، می‌توان مدل را مطمئن دانست؛ در مقابل، پراکندگی زیاد پاسخ‌ها نشان‌دهنده عدم اطمینان مدل است. این روش جایگزین عملی و مؤثری برای پرس‌وجو مستقیم از «اطمینان خودارزیابی‌شده مدل» به شمار می‌رود؛ قابلیتی که مدل‌های کوچک‌تر معمولا به دلیل محدودیت در خودآگاهی و توانایی استدلال درون‌نگرانه از آن بی‌بهره‌اند.
\cite{b81}
در مواردی که
گائوکرنا-\lr{R}
عدم اطمینان نشان می‌دهد (یعنی چندین پاسخ متمایز تولید می‌کند)، از مدل پایه یعنی
\lr{aya-expanse-8b}
به‌عنوان یک تاییدکننده کمکی
\footnote{\lr{auxiliary verifier}}
استفاده می‌کنیم. پاسخ‌های تولیدشده توسط
گائوکرنا-\lr{R}
به
\lr{aya-expanse-8b}
ارائه می‌شود و این مدل مأمور می‌شود گزینه‌ای را انتخاب کند که کم‌ترین اطلاعات نادرست یا ناسازگار را داشته باشد.

در نتیجه، دو پیکربندی زیر را با هم مقایسه کردیم که در جدول
\ref{tab:med_opns_comparison}
خلاصه شده‌اند:
\begin{itemize}
\item
گائوکرنا-\lr{V}
 فقط با درخواست مستقیم و بدون هیچ‌گونه راهنمایی استدلالی ارزیابی می‌شود.
\item
به گائوکرنا-R درخواست زنجیره افکار داده می‌شود و در صورت بروز عدم اطمینان، پاسخ‌های تولیدشده آن توسط
\lr{aya-expanse-8b}
بررسی و معتبرترین پاسخ انتخاب می‌شود.
\end{itemize}



	\begin{table}[ht]
		\centering
		\begin{tabular}{|l|c|c|}  
			\hline
			\textbf{} & \textbf{gaokerena-R} & \textbf{gaokerena-V}  \\ 
			& \textbf{+} &   \\
			& \textbf{\lr{aya-expanse-8b}}  &     \\ 
                        & \textbf{(verifier)}  &     \\ \hline
			MMLU- &  &    \\ 
			anatomy(fa)  & \lr{47.40}  & \textbf{\lr{48.14}}   \\ \hline
			MMLU- &   &      \\
			medical-genetics(fa) & \textbf{\lr{56.0}}  & \lr{53.0}   \\ \hline
			MMLU- &  &      \\
			college-medicine(fa) & \textbf{\lr{50.28}} & \lr{43.93}    \\ \hline
			MMLU- &    &    \\
			clinical-knowledge(fa) & \textbf{\lr{58.86}}  & \lr{55.47}  \\ \hline
			MMLU- &  &    \\
			professional-& \textbf{\lr{48.89}} & \lr{47.05}  \\
                        medicine(fa)& &      \\ \hline
			MMLU- &  &   \\
			college-biology(fa)& \textbf{\lr{54.86}} & \lr{47.22}   \\ \hline
			MMLU(avg) & \textbf{\lr{52.98}}  & \lr{49.31}   \\ \hline
			\lr{IBMSEE Sept2023} & \textbf{\lr{46.42}}  &\lr{38.69}   \\ \hline
                        prompt & \lr{COT for the main model} & \lr{Straight}   \\ 
                        &            \lr{Straight for the verifier}   &   \\ \hline
			inference time & $\approx 5 \times 35 + 8 s$ & $\approx 10s$  \\  \hline
		\end{tabular}
		\caption{ارزیابی دو پیکربندی}
		\label{tab:med_opns_comparison}
	\end{table}


