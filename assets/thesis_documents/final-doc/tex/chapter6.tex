% !TeX root=../main.tex
\chapter{استدلال در مدل های زبانی}
%\thispagestyle{empty} 
ظهور معماری ترنسفورمر
\footnote{\lr{Transformer}}
\cite{b5}
در سال 2017 نقطه‌ی عطفی بنیادین در تحول مدل‌های زبانی بزرگ به‌شمار می‌آید. این معماری با معرفی سازوکار توجه
\footnote{\lr{Attention}}
و جایگزینی آن به‌جای پردازش متوالی، بسیاری از محدودیت‌های مدل‌های پیشین ــ از جمله پدیده‌ی محو شدن گرادیان‌ها و ناتوانی در مدل‌سازی وابستگی‌های بلندمدت ــ را برطرف ساخت. بدین‌ترتیب، امکان موازی‌سازی کامل در فرایند آموزش فراهم شد و مدل توانست ساختارهای زبانی پیچیده را با دقت و کارایی بسیار بالاتری درک و بازنمایی کند.    

در این فصل، تمرکز بر بررسی توانایی استدلال در معماری ترنسفورمر و رویکردهای نوین برای بهبود آن است. هرچند این معماری در وظیفه‌ی پیش‌بینی توکن بعدی عملکردی خیره‌کننده دارد، اما نحوه‌ی استدلال آن عموما الگومحور است تا منطق‌محور. به بیان دیگر، تمامی مدل‌های زبانی مدرن که بر پایه‌ی ترنسفورمر ساخته شده‌اند، در هسته‌ی خود از همان ضعف بنیادی رنج می‌برند: ناتوانی در درک و بازتولید فرایندهای استدلالی عمیق و مبتنی بر منطق.

\section{ناتوانی معماری ترنسفورمر در تفکر سیستم دو}
در سال 2019، در کنفرانس
\lr{NeurIPS}،
یوشوا بنجیو—یکی از چهره‌های پیشگام در حوزه‌ی یادگیری عمیق به یکی از محدودیت‌های بنیادین سیستم‌های یادگیری عمیق امروزی، از جمله مدل‌های زبانی، اشاره کرد: ناتوانی در انجام وظایفی که نیازمند مهارت‌های استدلالی قوی هستند.
\cite{b69}
\footnote{سخنرانی بنجیو اهمیت بسزایی داشت و مفهوم «تفکر سیستم دو» را در هوش مصنوعی برجسته کرد. درس دکتر رهبان در دانشگاه شریف با این عنوان، راهنمایی کلیدی برای پایان‌نامه‌ی حاضر بوده است.}
به‌رغم عملکرد چشمگیر این سیستم‌ها در وظایف شهودی و ادراکی نظیر تشخیص تصویر، ترجمه‌ی ماشینی یا تولید متن آن‌ها در مواجهه با مسائلی که مستلزم استدلال منطقی، درک روابط علّی و پردازش شناختی عمیق هستند، عملکرد ضعیفی از خود نشان می‌دهند. در واقع، بسیاری از اشتباهات ساده و احمقانه‌ی مدل‌های زبانی مانند ناتوانی در حل مسائل ریاضی ابتدایی یا استنتاج‌های منطقی آشکار را می‌توان با همین محدودیت در تفکر سیستم دو توضیح داد.
این مشاهده یادآور تمایز مطرح‌شده توسط دنیل کانمن در علوم شناختی
\cite{b70}
میان دو نوع تفکر است: تفکر سریع که بنجیو آن را «تفکر سیستم یک» می‌نامد و تفکر آهسته که بنجیو آن را «تفکر سیستم دو» می‌خواند. تفکر سریع، ماهیتی شهودی، واکنشی و خودکار دارد و با نقاط قوت سیستم‌های فعلی هوش مصنوعی هم‌راستا است؛ در مقابل، تفکر آهسته فرایندی آگاهانه، تحلیلی و منطقی است که مستلزم توانایی در برنامه‌ریزی، استدلال و بازنمایی مفاهیم انتزاعی می‌باشد.
به بیان دیگر، شبکه‌های عصبی عمیق و به‌ویژه مدل‌های زبانی مبتنی بر ترنسفورمر عمدتا در سطح تفکر سیستم یک، یعنی شناخت شهودی، عمل می‌کنند و فاقد شناخت منطقی یا استدلال علّی تفکر سیستم دو هستند. این شکاف میان شهود و منطق، چالشی اساسی در مسیر توسعه‌ی نسل بعدی مدل‌های زبانی و سامانه‌های هوش مصنوعی با قابلیت تفکر مشابه انسان به شمار می‌رود.

\section{طراحی یک معماری دارای قابلیت تفکر سیستم دو}
بهترین رویکرد برای غلبه بر ناتوانی ترنسفورمرها در تفکر سیستم دو، توسعه‌ی یک معماری جدید است که بتواند این قابلیت را به‌طور ذاتی در خود داشته باشد.
اما طراحی و پیاده‌سازی چنین معماری‌ای کار ساده‌ای نیست!

چنین معماری‌ای باید دارای توانایی تعمیم خارج از توزیع
\footnote{\lr{Out-of-Distribution Generalization}}
نیز باشد؛ به این معنا که مدل بتواند مفاهیم و روابطی را یاد بگیرد که به‌صورت صریح و مستقیم در داده‌های آموزشی وجود ندارند. به بیان دیگر، سیستم باید قادر باشد از دانش موجود در داده‌ها به موقعیت‌های جدید و نادیده تعمیم دهد ــ ویژگی‌ای که برای استدلال واقعی و تفکر سطح بالا ضروری است.

در سال‌های اخیر، پژوهشگران چندین مدل و معماری جایگزین را برای بهبود توانایی استدلال در شبکه‌های عصبی پیشنهاد داده‌اند. برای مثال، یکی از این تلاش‌ها معماری‌ای به نام
\lr{RIM}
\cite{b71}
بود که توسط یوشوا بنجیو معرفی شد. یا معماری مدل استدلال سلسله‌مراتبی
\footnote{\lr{Hierarchical Reasoning Model}}
\cite{b72}
که با الهام از سلسله مراتبی بودن تفکر انسان پیشنهاد شده است؛

با این حال،
مدل های پیشنهاد شده
در عمل معماری مقیاس‌پذیری نبوده و نتوانسته اند در مقیاس‌های بزرگ عملکرد قابل‌قبولی ارائه دهند. به همین دلیل، نمی‌توان آن ها را یک پیشنهاد موفق برای حل مشکل استدلال در مدل‌های مبتنی بر ترنسفورمر دانست.

در نتیجه، همچنان یکی از چالش‌های باز در حوزه‌ی یادگیری عمیق و مدل‌های زبانی بزرگ، یافتن معماری‌ای کارا، مقیاس‌پذیر، دارای توان استدلالی و برخوردار از قابلیت تعمیم خارج از توزیع است؛ معماری‌ای که بتواند محدودیت‌های ذاتی ترنسفورمرها را پشت سر بگذارد.

\section{
بهبود توانایی دلیل آوری مدل های زبانی مبتنی بر ترنسفورمر
}
تا زمانی که هنوز معماری‌ای با قابلیت استدلال ذاتی
\footnote{\lr{Intrinsic Reasoning Capability}}
در دسترس نداریم، ناچاریم همچنان با معماری ترنسفورمر کار کنیم و به‌نوعی بر محدودیت‌ها و ضعف‌های ذاتی آن غلبه نماییم.

با وجود تمام پیشرفت‌ها، ترنسفورمرها هنوز فاقد سازوکار درونی برای استدلال گام‌به‌گام، تعمیم منطقی و درک علیت هستند. با این حال، از آن‌جا که در حال حاضر موثرترین و مقیاس‌پذیرترین معماری در حوزه‌ی مدل‌های زبانی محسوب می‌شوند، راهبرد عملی این است که به جای کنار گذاشتن آن‌ها، راهکارهایی برای تقویت توانایی استدلالی‌شان طراحی و به کار گرفته شود.روش‌های گوناگونی برای این هدف پیشنهاد شده است که برای اطلاعات بیشتر میتوانید در مقاله مروری آقای پان
\cite{b73}
در این زمینه مراجعه کنید.

در این بخش، به بررسی مهم‌ترین این رویکردها و روش‌هایی که می‌توانند به بهبود توانایی استدلالی مدل‌های مبتنی بر ترنسفورمر منجر شوند، خواهیم پرداخت.

\subsection{
روش های مبتنی بر هوش مصنوعی عصبی-نمادین
}
در حوزه‌ی هوش مصنوعی، دو مکتب فکری اصلی وجود دارد: نمادگرایی
\footnote{\lr{Symbolism}}
و ارتباط‌گرایی
\footnote{\lr{Connectionism}}
.

در مکتب نمادگرایی، هدف اصلی این است که منطق، قوانین و روابط صریح میان مفاهیم جمع‌آوری شده و در قالب یک مدل منطقی یا قاعده‌محور نمایش داده شود. این رویکرد بر پایه‌ی استدلال نمادین استوار است؛ یعنی سیستم تلاش می‌کند با استفاده از قواعد صریحی که توسط انسان تعریف شده‌اند، به نتیجه برسد.

در مقابل، مکتب ارتباط‌گرایی بر پایه‌ی ایده‌ی یادگیری از داده‌ها شکل گرفته است. در این رویکرد، به‌جای تعریف قوانین منطقی، حجم زیادی از داده به مدل داده می‌شود تا خود سیستم از درون داده‌ها الگوها و روابط را کشف کند. شبکه‌های عصبی مصنوعی و به‌ویژه مدل‌های عمیق 
\footnote{\lr{Deep Learning}}
از نمونه‌های شاخص این مکتب هستند.

با معرفی معماری ترنسفورمر، مکتب ارتباط‌گرایی به شکل چشمگیری غالب شد و تقریبا تمامی پژوهش‌های پیشرفته‌ی حوزه‌ی هوش مصنوعی حول آن متمرکز گردید. دلیل این غلبه روشن است:
جمع‌آوری داده‌های عظیم بسیار ساده‌تر از استخراج و تعریف قوانین منطقی دقیق است، و مدل‌های ارتباط‌گرا با استفاده از این داده‌های گسترده می‌توانند عملکردی چشمگیر در وظایف گوناگون مانند ترجمه، تولید متن، بینایی ماشین و غیره داشته باشند.

با این حال، همان‌طور که پیش‌تر اشاره شد، ترنسفورمرها ضعف بزرگی دارند: ناتوانی در استدلال!
این مدل‌ها اگرچه در شناسایی الگوها و پیش‌بینی توالی‌ها بسیار قدرتمندند، اما فاقد سازوکار درونی برای انجام استدلال منطقی و تفکر نظام‌مند (تفکر سیستم دو) هستند.
از آن‌جا که تاکنون معماری‌ای با قابلیت استدلال ذاتی معرفی نشده است، تمامی مدل‌های مبتنی بر ارتباط‌گرایی نیز همین ضعف بنیادی را به ارث برده‌اند.
در مقابل، رویکردهای نمادین از این نظر برترند که توانایی استدلال و نتیجه‌گیری منطقی را به‌صورت ذاتی در خود دارند، اما مشکل بزرگ آن‌ها عدم مقیاس‌پذیری
\footnote{\lr{Unscalability}}
است؛ یعنی پیاده‌سازی و گسترش آن‌ها برای مسائل واقعی و داده‌های بزرگ بسیار دشوار است.

برای رفع این شکاف، گروهی از پژوهشگران پیشنهاد یک رویکرد میان‌رشته‌ای جدید را مطرح کرده‌اند که ترکیبی از این دو مکتب است:
رویکرد عصبی-نمادین
\footnote{\lr{Neuro-Symbolic AI}}
.
در این دیدگاه، تلاش می‌شود از قدرت یادگیری و تعمیم مدل‌های عصبی (ارتباط‌گرا) در کنار توان استدلال و شفافیت سیستم‌های نمادین استفاده شود تا هوشی ترکیبی و متوازن به‌دست آید؛ هوشی که هم بتواند از داده بیاموزد، و هم به‌طور منطقی بیندیشد.
\cite{b74}

با این حال، یوشوا بنجیو معتقد است که این مسیر، راه‌حل نهایی مناسبی نیست و ممکن است با مقیاس‌پذیری در تضاد باشد. او تأکید می‌کند که به جای ترکیب دو مکتب مجزا، بهترین راه، توسعه‌ی معماری‌هایی است که قابلیت استدلال را به‌طور ذاتی در درون خود داشته باشند؛ یعنی سامانه‌هایی که بتوانند استدلال، تعمیم و یادگیری را در یک چارچوب واحد و منسجم ادغام کنند.

\subsection{
روش های مبتنی بر راهنمایی مدل زبانی توسط یک مدل پاداش
}

یکی از روش‌های بهبود مهارت‌های استدلالی یک مدل زبانی، هدایت فرآیند رمزگشایی آن با استفاده از یک مدل پاداش است. مدل پاداش می‌تواند به دو صورت باشد: مدل پاداش خروجی
\footnote{\lr{Output Reward Model}}
و مدل پاداش فرآیند
\footnote{\lr{Process Reward Model}}
\cite{b75}
.
مدل پاداش خروجی بر ارزیابی کیفیت پاسخ نهایی تولیدشده توسط مدل زبانی تمرکز دارد. این مدل به خروجی‌ها امتیاز می‌دهد و بر اساس معیارهای مشخص، مانند دقت، انسجام یا ارتباط با پرس‌وجو، آن‌ها را رتبه‌بندی می‌کند. از سوی دیگر، مدل پاداش فرآیند به مراحل میانی استدلال مدل توجه می‌کند. این مدل هر گام از فرآیند تفکر یا حل مسئله را بررسی و ارزیابی می‌کند تا اطمینان حاصل شود که مسیر استدلال منطقی و بهینه است.
استفاده از این دو نوع مدل پاداش می‌تواند به بهبود عملکرد مدل زبانی در وظایف پیچیده کمک کند. برای مثال، در حل مسائل ریاضی یا پاسخ به سؤالات استدلالی، مدل پاداش فرآیند می‌تواند مدل را به سمت رویکردهای گام‌به‌گام و دقیق‌تر هدایت کند، در حالی که مدل پاداش خروجی کیفیت نهایی پاسخ را تضمین می‌کند. ترکیب این دو مدل می‌تواند به ایجاد پاسخ‌هایی منجر شود که نه تنها درست هستند، بلکه فرآیند رسیدن به آن‌ها نیز شفاف و قابل‌اعتماد است.
یکی از کارهایی که سعی در بهبود توانایی دلیل آوری کرده است مدل
\lr{Medsss}
\cite{b35}
است که در فصل کارهای پیشین در مورد آن توضیحات لازمه داده شده است.

\subsection{
روش های مبتنی بر تمرین روی داده های دلیل آوری
}
یکی دیگر از روش‌های بهبود مهارت‌های استدلالی یک مدل زبانی، آموزش آن با داده‌های استدلالی است. با انجام این کار، مدل زبانی می‌تواند یاد بگیرد که چگونه استدلال را تقلید کند یا استدلال‌هایی را که قبلا در داده‌های آموزشی خود مشاهده کرده است، بازیابی کند. این رویکرد به مدل کمک می‌کند تا در مواجهه با مسائل پیچیده، پاسخ‌هایی منطقی‌تر و ساختاریافته‌تر ارائه دهد.
\cite{b76}

در این روش، داده‌های آموزشی شامل نمونه‌هایی از فرآیندهای استدلالی، مانند حل گام‌به‌گام مسائل ریاضی، تحلیل‌های منطقی، یا استدلال‌های مبتنی بر شواهد هستند. با قرار گرفتن در معرض این داده‌ها، مدل زبانی نه تنها یاد می‌گیرد که پاسخ‌های درست تولید کند، بلکه می‌آموزد که چگونه به طور نظام‌مند به آن پاسخ‌ها برسد. این فرآیند به بهبود توانایی مدل در درک عمیق‌تر پرسش ها و ارائه پاسخ‌هایی با کیفیت بالاتر کمک می‌کند. در حقیقت مدل زبانی پایه با تمرین روی داده های استدلالی یاد میگیرد که فرآیند استدلال را شبیه سازی کند و ما تصور کنیم که در حال دلیل آوری است در حالی که معماری که آن مدل روی آن بنا شده توانایی استدلال را ندارد این پدیده ای است که به آن توهم دلیل آوری
\footnote{\lr{delusion of thinking}}
میگویند.
\cite{b77}
\cite{b78}
یکی از مهم‌ترین کارهایی که این رویکرد را با موفقیت پیاده‌سازی کرده، مدل
\lr{DeepSeek-R}
\cite{b39}
است. این مدل با استفاده از مجموعه داده‌های استدلالی گسترده و متنوع آموزش دیده است و توانسته است عملکرد قابل‌توجهی در وظایف استدلالی پیچیده از خود نشان دهد.
\lr{DeepSeek-R}
با بهره‌گیری از تکنیک‌های پیشرفته در آموزش مدل‌های زبانی، قادر است استدلال‌های منطقی را با دقت بالا تولید کند و حتی در مواردی که نیاز به تفکر چندمرحله‌ای است، عملکردی رقابتی با مدل‌های بزرگ‌تر ارائه دهد. برای اطلاعات بیشتر درباره این مدل و جزئیات رویکرد آن، می‌توانید به بخش کارهای پیشین مراجعه کنید.




