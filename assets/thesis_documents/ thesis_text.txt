دیباچه

هدف پژوهش
هدف از این پژوهش، توسعه یک مدل زبانی پزشکی فارسی بر پایه استدلال است که قابلیت اجرا روی دستگاه‌های محلی را داشته باشد. اجرا روی دستگاه‌های محلی از آن جهت حائز اهمیت است که داده‌های پزشکی اغلب حساس و خصوصی هستند و ارسال آنها به سرورهای خارجی ممکن است خطرات جدی برای حریم خصوصی بیماران ایجاد کند.

کاربرد پژوهش

کاربرد مدل‌های زبانی پزشکی
مدل‌های زبانی در سال‌های اخیر با استفاده از داده‌های بسیار گسترده‌تر و معماری‌های پیشرفته‌تر به پیشرفت‌های چشمگیری دست یافته‌اند. این مدل‌ها توانایی درک بهتر مفاهیم، تولید متن‌های طبیعی‌تر و پاسخ‌دهی دقیق‌تر به سوالات را پیدا کرده‌اند.

این پیشرفت‌ها منجر به افزایش چشمگیر کاربرد هوش مصنوعی در حوزه‌های مختلف، به‌ویژه در زمینه پزشکی، شده است. امروزه در حوزه پزشکی، مدل‌های زبانی مبتنی بر یادگیری ژرف نقش مهمی در تحلیل داده‌های پزشکی، بهبود دقت تشخیص بیماری‌ها، ارائه پیشنهادهای درمانی دقیق‌تر و افزایش کیفیت مراقبت از بیماران ایفا می‌کنند. علاوه بر این، این فناوری به بهینه‌سازی سیستم‌های اداری و کاهش بار کاری کادر درمانی کمک شایانی کرده است. به عنوان مثال، مدل‌های هوش مصنوعی قادرند با تحلیل داده‌های حاصل از پرونده‌های پزشکی، الگوهای مرتبط با بیماری‌ها را شناسایی کنند و اطلاعات ارزشمندی را برای تصمیم‌گیری سریع‌تر و دقیق‌تر در اختیار پزشکان قرار دهند.

این مدل‌ها همچنین می‌توانند نقش مهمی در تکمیل مشاوره‌های پزشکی ایفا کرده و به پزشکان در ارائه اطلاعات دقیق‌تر و سریع‌تر کمک کنند و حتی شاید در آینده‌ای نه چندان دور بتوانند جای پزشکان را در مشاوره‌های پزشکی بگیرند.

این تحول نه تنها به افزایش کارایی و بهره‌وری در سیستم‌های درمانی منجر شده است، بلکه تجربه کلی بیماران را نیز بهبود بخشیده و امکان ارائه خدمات درمانی بهتر و مؤثرتر را فراهم کرده است. به همین دلیل، توسعه و استفاده از مدل‌های زبانی پزشکی همچنان مورد توجه پژوهشگران و متخصصان قرار دارد.

کاربرد مدل‌های زبانی پزشکی دارای قابلیت استدلال
پزشکی به‌عنوان یک علم تجربی و کاربردی، بیش از هر چیز به استدلال دقیق وابسته است. تشخیص بیماری، انتخاب درمان، پیش‌بینی پیامد و حتی آموزش پزشکی، همگی بر پایه زنجیره‌های منطقی، تحلیل داده‌های بالینی و استنتاج از شواهد بنا شده‌اند. از آنجا که پزشکی علمی کاملاً وابسته به استدلال است، توسعه یک مدل زبانی که دارای قابلیت‌های استدلال برتری باشد می‌تواند بسیار تحول‌آفرین باشد. این مدل‌ها نه‌تنها می‌توانند اطلاعات را بازیابی کنند، بلکه می‌توانند دلیل بیاورند، احتمالات را مقایسه کنند، تناقضات را شناسایی کنند و تصمیمات را توجیه‌پذیر سازند. بنابراین توسعه این نوع از مدل‌های زبانی در حوزه پزشکی بسیار مفید است.

کاربرد مدل‌های زبانی پزشکی فارسی
با وجود پیشرفت‌های چشمگیر در توسعه مدل‌های زبانی پزشکی به زبان انگلیسی، در حوزه زبان فارسی هنوز کار چندانی صورت نگرفته است. این در حالی است که در سراسر جهان میلیون‌ها نفر تنها قادر به استفاده از زبان فارسی هستند؛ بنابراین تلاش برای توسعه یک مدل زبانی پزشکی در زبان فارسی می‌تواند گامی بزرگ رو به جلو در ارتباطات و خدمات درمانی کشورهای فارسی‌زبان باشد.

مراحل انجام پایان‌نامه
این پایان‌نامه در دو فاز اصلی طراحی و اجرا شده است. فاز نخست به جمع‌آوری دادگان پزشکی فارسی و توسعه مدلی با نام گائوکرنا-V اختصاص دارد که فاقد توانایی استدلال بوده و بیشتر بر درک سریع و شهودی زبان تمرکز دارد (درکی که در علم رفتارشناسی به آن «درک سیستم یک» می‌گویند، در مقابل درک آهسته و نیازمند استدلال که «درک سیستم دو» نامیده می‌شود).

از این فاز، مقاله‌ای با عنوان «اهرم قرار دادن داده‌های آنلاین برای بهبود دانش پزشکی یک مدل زبانی کوچک پزشکی فارسی» استخراج شده است که به تشریح فرآیند جمع‌آوری داده‌ها و نحوه بهینه‌سازی دانش پزشکی مدل می‌پردازد.

در فاز دوم ابتدا تکنیک‌های جدیدی برای ارتقای توانایی استدلال و درک سیستم دو معرفی شد و سپس مدل گائوکرنا-R توسعه یافت. از این فاز نیز مقاله‌ای با عنوان «بهبود مهارت‌های استدلال در مدل‌های زبانی پزشکی فارسی کوچک می‌تواند از آموزش داده‌های بزرگ‌مقیاس پیشی بگیرد» استخراج گردید.

مقاله نخست در سی و دومین کنفرانس ملی و دهمین کنفرانس بین‌المللی مهندسی پزشکی ایران و مقاله دوم در یازدهمین کنفرانس بین‌المللی پردازش سیگنال و سیستم‌های هوشمند منتشر شده است.

اطلاعات دو فاز پایان‌نامه
گائوکرنا-R        گائوکرنا-V
مخزن گیت‌هاب:      مخزن گیت‌هاب:
مخزن پارامترها:     مخزن پارامترها:
پیوند مقاله:       پیوند مقاله:
هزینه: ۷۰ دلار      هزینه: ۳۰۰ دلار
توانایی استدلال: بله    توانایی استدلال: خیر
منتشر شده در: یازدهمین کنفرانس بین‌المللی پردازش سیگنال و سیستم‌های هوشمند  منتشر شده در: سی و دومین کنفرانس ملی و دهمین کنفرانس بین‌المللی مهندسی پزشکی ایران

ساختار پایان‌نامه
در این پایان‌نامه، ساختار فصل‌ها به گونه‌ای طراحی شده است که مراحل مختلف پژوهش به صورت منظم و هدفمند ارائه شوند. فصل دوم به بررسی کارهای پیشین اختصاص دارد. در فصل سوم، به دلیل نبود دادگان پزشکی در زبان فارسی، فرآیند گردآوری و آماده‌سازی این دادگان به‌طور دقیق تشریح می‌شود. در فصل چهارم، با استفاده از دادگان فصل سوم، مدل اولیه با نام گائوکرنا-V (که نامی است الهام‌گرفته از درخت افسانه‌ای شفا و جاودانگی در اساطیر زرتشتی) معرفی و تحلیل می‌گردد. در فصل پنجم، توانایی‌های استدلال در مدل‌های هوش مصنوعی و چالش‌های آن بررسی می‌شود. در فصل ششم، با معرفی تکنیک‌های جدید بهبود استدلال، مدل پیشرفته‌تر گائوکرنا-R ارائه و ویژگی‌های آن شرح داده می‌شود. در نهایت، فصل پایانی به جمع‌بندی نتایج و پیشنهادهایی برای تحقیقات آینده اختصاص دارد.


ادبیات موضوع

مقدمه
در این فصل به بررسی مفاهیم مدل‌های زبانی، انواع آن و چگونگی سنجش آن‌ها می‌پردازیم. همچنین انواع سیستم‌های پرسش و پاسخ را بررسی می‌کنیم تا درک بهتری از عملکرد و کاربردهای مختلف این سیستم‌ها به دست آوریم.

مدل‌های زبانی
مدل‌های زبانی ابزارهای پیشرفته‌ای هستند که برای پردازش و تولید زبان طبیعی طراحی شده‌اند. این مدل‌ها با استفاده از یادگیری ماشین و به‌ویژه یادگیری عمیق، توانایی درک و تولید متن دارند. در حقیقت، وظیفه اصلی مدل‌های زبانی پیش‌بینی توکن بعدی بر اساس متن قبلی است. این مدل‌ها انواع مختلفی دارند که در ادامه بررسی می‌شوند.

مدل‌های زبانی آماری
مدل‌های زبانی ان‌گرام ابتدایی‌ترین مدل‌های زبانی هستند که در دهه نود میلادی به عنوان جایگزینی برای ترجمه ماشینی مبتنی بر قانون معرفی شدند. این مدل‌ها برای پیش‌بینی توکن بعدی از فراوانی ان‌گرام‌ها در پیکره موجود استفاده می‌کنند. به عنوان مثال در مدل دو‌گرام، احتمال وقوع یک کلمه تنها بر اساس کلمه قبلی محاسبه می‌شود.

مدل‌های زبانی بازگشتی
شبکه‌های عصبی بازگشتی نوعی از شبکه‌های عصبی مصنوعی هستند که به‌طور خاص برای پردازش توالی‌ها طراحی شده‌اند. چون زبان نیز یک توالی از توکن‌هاست، می‌توان از این شبکه‌ها به عنوان مدل زبانی استفاده کرد. ویژگی اصلی این شبکه‌ها وجود حلقه‌های بازگشتی است که اطلاعات را از مراحل قبلی به مراحل بعدی منتقل می‌کند و وابستگی‌های زمانی و ترتیبی را مدل‌سازی می‌کند.

اما شبکه‌های عصبی بازگشتی ساده در مدل‌سازی وابستگی‌های بلندمدت با مشکل جدی مواجه هستند. این مشکل در زبان‌های طبیعی بسیار رایج است و باعث شده مدل‌های مبتنی بر شبکه‌های بازگشتی ساده عملکرد مطلوبی نداشته باشند. هرچند در نسخه‌های پیشرفته‌تر مانند ال‌اس‌تی‌ام تلاش‌هایی برای حل این مشکل شده، اما همچنان محدودیت‌هایی وجود دارد.

مدل‌های زبانی مبتنی بر ترنسفورمر
مدل‌های زبانی بازگشتی به دلیل ماهیت توالی‌گونه و مشکل وابستگی بلندمدت، سرعت پایینی داشتند. مقاله «توجه همه چیزی است که نیاز داری» با معرفی معماری ترنسفورمر توانست هر دو مشکل را حل کند. این معماری از مکانیزم توجه استفاده می‌کند که به مدل اجازه می‌دهد به‌طور همزمان به تمام ورودی‌ها توجه کند و وابستگی‌های بلندمدت را به‌راحتی شناسایی نماید. همچنین به دلیل قابلیت پردازش موازی، سرعت بسیار بالایی دارد و با پردازنده‌های گرافیکی به‌خوبی کار می‌کند.

مدل‌های مبتنی بر ترنسفورمر به سه دسته تقسیم می‌شوند:

مدل‌های فقط رمزگذار
این مدل‌ها تنها از بخش رمزگذار ترنسفورمر استفاده می‌کنند و برای درک و تحلیل متن طراحی شده‌اند. مناسب وظایفی مانند تحلیل احساسات، دسته‌بندی متن و استخراج ویژگی هستند، اما نمی‌توانند متن جدید تولید کنند. نمونه معروف: برت.

مدل‌های فقط رمزگشا
این مدل‌ها تنها از بخش رمزگشای ترنسفورمر استفاده می‌کنند و به‌صورت تک‌جهته عمل می‌کنند؛ یعنی فقط به توکن‌های قبلی دسترسی دارند. هدف اصلی آن‌ها پیش‌بینی توکن بعدی و تولید متن است. در تولید متن، چت‌بات‌ها و ترجمه ماشینی بسیار مؤثرند. نمونه معروف: جی‌پی‌تی.

مدل‌های رمزگذار-رمزگشا
این مدل‌ها از هر دو بخش رمزگذار و رمزگشا استفاده می‌کنند و در وظایف پیچیده مانند ترجمه ماشینی، خلاصه‌سازی و تولید گفتار کاربرد دارند. نمونه معروف: تی۵.

سیستم‌های پرسش و پاسخ
سیستم‌های پرسش و پاسخ با استفاده از تکنیک‌های پردازش زبان طبیعی به کاربران امکان می‌دهند سؤالات خود را به زبان طبیعی مطرح کنند و پاسخ دقیق دریافت نمایند. این سیستم‌ها دو نوع اصلی دارند: استخراجی و تولیدی.

سیستم‌های پرسش و پاسخ استخراجی
در این نوع، پاسخ مستقیماً از متن موجود استخراج می‌شود و معمولاً از مدل‌های فقط رمزگذار مانند برت استفاده می‌کنند.

سیستم‌های پرسش و پاسخ تولیدی
در این نوع، مدل به جای استخراج، پاسخ را خودش تولید می‌کند و به دانش داخلی خود تکیه دارد. بنابراین از مدل‌های فقط رمزگشا یا رمزگذار-رمزگشا استفاده می‌شود. در پایان‌نامه حاضر نیز ما یک سیستم پرسش و پاسخ تولیدی پزشکی فارسی طراحی کرده‌ایم.

شیوه‌های سنجش مدل‌های زبانی
سنجش دانش یک مدل زبانی به‌ویژه در حوزه پزشکی بسیار مهم است. در این پژوهش از دو روش اول برای ارزیابی مدل‌های خود استفاده کرده‌ایم:

۱. سنجش بر اساس پاسخگویی به سؤالات چهارگزینه‌ای
یکی از رایج‌ترین روش‌ها استفاده از مجموعه داده‌هایی مانند ام‌ام‌ال‌یو است که شامل هزاران سؤال چهارگزینه‌ای در موضوعات مختلف از جمله پزشکی می‌باشد. این روش امکان مقایسه دقیق بین مدل‌ها را فراهم می‌کند.

۲. سنجش با مدل داور
در این روش یک مدل زبانی دیگر به عنوان قاضی عمل می‌کند و کیفیت پاسخ‌های مدل اصلی را با معیارهایی مانند صحت، کامل بودن و روانی ارزیابی می‌کند.

۳. سنجش بر اساس استنتاج زبان طبیعی
با استفاده از مجموعه داده‌هایی که پاسخ‌های انسانی به همراه توضیحات الزامی و مفید دارند، می‌توان کامل بودن و صحت پاسخ مدل را با روش استنتاج زبان طبیعی بررسی کرد.

۴. سنجش بر اساس امتیاز برت
در این روش، شباهت معنایی پاسخ مدل با پاسخ صحیح با استفاده از مدل برت و شباهت کسینوسی محاسبه می‌شود.

یادگیری تقویتی در مدل‌های زبانی
پس از داشتن یک مدل زبانی پایه، می‌توان با استفاده از یک مدل یا تابع پاداش و الگوریتم‌های یادگیری تقویتی، مدل را به‌گونه‌ای تنظیم کرد که پاسخ‌های بهتر، دقیق‌تر، مفیدتر و هم‌راستا با ارزش‌های انسانی تولید کند. این فرآیند باعث کاهش پاسخ‌های نادرست، جانبدارانه یا مخرب و افزایش ایمنی و کیفیت کلی می‌شود.

یادگیری تقویتی با بازخورد انسانی یا هوش مصنوعی
علاوه بر بازخورد انسانی، می‌توان از بازخورد هوش مصنوعی (مدل‌های پیشرفته‌تر یا سیستم‌های ارزیابی خودکار) نیز استفاده کرد که هزینه و زمان را به شدت کاهش می‌دهد.

الگوریتم‌های بهینه‌سازی مدل زبانی
مهم‌ترین الگوریتم‌های مورد استفاده عبارتند از:
- بهینه‌سازی سیاست مجاورتی (پرکاربرد و پایدار)
- بهینه‌سازی سیاست بر پایه پاداش گروهی
- بهینه‌سازی مستقیم ترجیحات (ساده‌تر و پایدارتر، بدون نیاز به مدل پاداش جداگانه)
- بهینه‌سازی مستقیم تابع کیو (بر پایه فرآیند تصمیم مارکوف)

هر یک از این روش‌ها با هدف افزایش کارایی، پایداری و هم‌راستایی مدل با ترجیحات و ارزش‌های انسانی توسعه یافته‌اند و نقش مهمی در پیشرفت اخیر مدل‌های زبانی ایفا کرده‌اند.

بررسی کارهای پیشین

مقدمه
با وجود پیشرفت‌های بسیار بزرگ در توسعه مدل‌های زبانی پزشکی به زبان انگلیسی مانند مدپالم و مد-جمینی، متأسفانه در حوزه زبان فارسی تقریباً هیچ کار جدی و جامعی انجام نشده است. بنابراین می‌توان گفت در این زمینه با یک صفحه تقریباً سفید روبه‌رو هستیم. هدف این پایان‌نامه برداشتن گامی مؤثر در جهت پر کردن این خلأ و توسعه مدل‌های زبانی پزشکی فارسی است.  
در ادامه به بررسی مهم‌ترین کارهای پیشین در حوزه زبان انگلیسی، زبان فارسی و همچنین روش‌های بهبود قابلیت استدلال در مدل‌های زبانی می‌پردازیم.

کارهای پیشین در حوزه زبان انگلیسی

مدل‌های مدپالم  
مدپالم و مدپالم۲ از مدل‌های بزرگ پزشکی هستند که توسط گوگل توسعه یافته‌اند. این مدل‌ها با داده‌های تخصصی پزشکی و بالینی آموزش دیده‌اند و هدف اصلی‌شان پاسخگویی دقیق به پرسش‌های پزشکی، کمک به تصمیم‌گیری بالینی و دسترسی آسان به اطلاعات پزشکی است. این مدل‌ها در آزمون‌های استاندارد پزشکی عملکردی نزدیک به سطح متخصصان پزشکی نشان داده‌اند.

مدل چت‌دکتر  
این مدل یکی از نزدیک‌ترین کارها به فاز اول پایان‌نامه حاضر است. داده‌های آموزشی آن از دو سایت معروف پرسش و پاسخ پزشکی جمع‌آوری شده و پس از فیلتر کردن، حدود صد هزار جفت پرسش و پاسخ باکیفیت بالا برای تنظیم دقیق مدل لاما استفاده شده است. همچنین از روش تولید مبتنی بر بازیابی اطلاعات بهره برده تا پاسخ‌های دقیق‌تر و به‌روزتری ارائه دهد.

مدل‌های میرکَت  
این مدل‌ها با استخراج زنجیره‌های تفکر از کتاب‌های درسی پزشکی و تنظیم دقیق مدل پایه بر روی این داده‌ها ساخته شده‌اند. هدف اصلی میرکَت شبیه‌سازی فرآیندهای استدلالی و تصمیم‌گیری پزشکان است و شباهت زیادی به فاز دوم پایان‌نامه ما دارد.

مدل مدموبایل  
این مدل یک مدل کوچک پزشکی است که بر پایه مدل فی-۳ مینی ساخته شده و با ترکیبی از داده‌های مصنوعی و انسانی تنظیم دقیق شده تا روی گوشی‌های همراه به‌صورت محلی اجرا شود و دسترسی آفلاین به اطلاعات پزشکی باکیفیت را فراهم کند.

کارهای پیشین در حوزه زبان فارسی
تحقیقات در حوزه مدل‌های زبانی پزشکی فارسی بسیار محدود و تقریباً همه بسته و غیرقابل دسترس هستند. همچنین تمام کارهای موجود بر رویکرد استخراجی (بازیابی پاسخ از متن موجود) تمرکز داشته‌اند و هیچ‌کدام رویکرد تولیدی (تولید پاسخ جدید) ندارند.

مدل سینا-برت  
احتمالاً اولین مدل زبانی پزشکی فارسی است که با آموزش مدل برت روی یک پیکره خزش‌شده پزشکی و مجموعه داده‌های پرسش و پاسخ فارسی ساخته شده. این مدل به‌دلیل استفاده از معماری فقط رمزگذار، اساساً نمی‌تواند پاسخ جدید تولید کند و تنها برای درک و استخراج اطلاعات مناسب است.

سیستم پرسش و پاسخ پزشکی دکتر ویسی و همکاران  
این سیستم شامل سه ماژول اصلی پردازش پرسش، بازیابی سند و استخراج پاسخ است و کاملاً استخراجی عمل می‌کند.

پایان‌نامه کارشناسی ارشد خانم لیلا دارابی  
از مدل‌هایی مانند پارس-برت برای بازیابی پاسخ‌های مرتبط استفاده کرده و با روش‌های طبقه‌بندی سؤالات و شناسایی موجودیت‌های پزشکی سعی در بهبود دقت پاسخگویی داشته است. این کار نیز کاملاً استخراجی است.

بهبود قابلیت استدلال در حوزه پزشکی

مدل مداس‌اس‌اس  
این چارچوب با استفاده از الگوریتم جست‌وجوی درختی مونت‌کارلو و تولید مسیرهای استدلالی مرحله‌به‌مرحله، سه مجموعه داده مصنوعی برای آموزش مدل سیاستی، بهینه‌سازی مستقیم ترجیحات و مدل پاداش فرآیند ساخته است. در نهایت مدلی تولید می‌کند که نه تنها پاسخ درست می‌دهد، بلکه فرآیند استدلال آن نیز منطقی و قابل ارزیابی است.

مدل مدریزِن  
از یک گراف دانش پزشکی ساختاریافته برای تبدیل جفت‌های پرسش-پاسخ به زنجیره‌های استدلالی گام‌به‌گام استفاده کرده و با تنظیم دقیق مدل پایه روی این داده‌ها، توانایی استدلال مدل را به‌طور چشمگیری افزایش داده است.

مدل هواتوجی‌پی‌تی-او۱  
یک چارچوب استدلال با هدایت اعتبارسنجی ارائه کرده که در آن یک مدل اعتبارسنج در حین تولید استدلال، مسیرها را بررسی و تأیید می‌کند. سپس با ترکیب تنظیم دقیق نظارت‌شده و یادگیری تقویتی، مدلی بسیار دقیق و قابل اعتماد در استدلال پزشکی ساخته شده است.

بهبود قابلیت استدلال در حوزه‌های دیگر

مدل دیپ‌سیک-آر  
بر پایه مدل دیپ‌سیک-وی۳ ساخته شده و با استفاده از الگوریتم بهینه‌سازی سیاست بر پایه پاداش گروهی و یادگیری تقویتی، توانایی استدلال را به‌طور قابل توجهی افزایش داده است. برای رفع مشکلات روانی زبان پس از یادگیری تقویتی، از یک مرحله تنظیم دقیق چندمرحله‌ای نیز استفاده کرده است.

چارچوب بهینه‌سازی ترجیحات فکری  
در این روش، مدل ابتدا چندین مسیر استدلالی متفاوت تولید می‌کند، سپس یک مدل داور بهترین و ضعیف‌ترین مسیرها را انتخاب می‌کند و با روش بهینه‌سازی مستقیم ترجیحات، مدل را آموزش می‌دهد تا مسیرهای استدلالی باکیفیت‌تر و منطقی‌تری تولید کند.

آموزش استدلال مدل‌های بزرگ به مدل‌های کوچک  
در این پژوهش نشان داده شده که می‌توان با تولید مسیرهای استدلالی توسط یک مدل بزرگ و تنظیم دقیق مدل کوچک روی این داده‌ها، توانایی استدلال را از مدل‌های بزرگ به مدل‌های کوچک منتقل کرد و عملکردی رقابتی با هزینه محاسباتی بسیار کمتر به‌دست آورد.

به‌طور خلاصه، در حالی که در زبان انگلیسی پیشرفت‌های عظیمی در مدل‌های زبانی پزشکی و استدلال‌محور رخ داده، در زبان فارسی تقریباً هیچ مدل تولیدی و استدلال‌محور پزشکی وجود ندارد. این پایان‌نامه اولین تلاش جامع برای پر کردن همزمان هر دو خلأ (مدل پزشکی فارسی + قابلیت استدلال قوی) به‌صورت کاملاً باز و قابل اجرا روی دستگاه‌های محلی است.

جمع‌آوری دادگان

مقدمه  
همان‌طور که پیش‌تر گفته شد، در حوزه زبان فارسی هیچ پیکره عمومی مناسب و هیچ مجموعه‌داده تخصصی پزشکی وجود نداشت. به همین دلیل مجبور شدیم تمام دادگان مورد نیاز این پایان‌نامه را خودمان از ابتدا جمع‌آوری کنیم. روش‌های به‌کاررفته شامل خزش داده‌ها از منابع فارسی و ترجمه ماشینی یا انسانی داده‌های موجود از زبان‌های دیگر بوده است.

پیکره پزشکی فارسی  
یکی از بزرگ‌ترین چالش‌های پژوهش در زبان فارسی، نبود پیکره متنی تخصصی پزشکی بود. ما یک پیکره شامل حدود ۹۰ میلیون توکن (تقریباً ۱۰۰ هزار مقاله کامل پزشکی) از مجلات و سایت‌های معتبر پزشکی فارسی خزش کردیم و به‌صورت عمومی منتشر کردیم. این پیکره بزرگ‌ترین پیکره متنی پزشکی فارسی موجود تا زمان نگارش این پایان‌نامه است.

مجموعه‌داده MF3QA  
برای آموزش مدل‌های تولیدی پزشکی، به مجموعه‌داده‌ای از پرسش‌ها و پاسخ‌های واقعی پزشک–بیمار نیاز داشتیم. ما بیش از ۱۸۰ هزار جفت پرسش‌وپاسخ واقعی را از تالارهای گفت‌وگوی پزشکی فارسی (عمدتاً «دکترهست» و «نی‌نی‌بان») خزش کردیم. سپس با فیلتر کردن دستی و خودکار، حدود ۸۰ درصد داده‌ها را به دلیل کوتاه بودن یا بی‌کیفیت بودن حذف کردیم و در نهایت مجموعه‌داده‌ای شامل ۲۰ هزار جفت پرسش‌وپاسخ باکیفیت بالا به نام MF3QA ایجاد کردیم که به‌صورت عمومی منتشر شده است.

منابع این مجموعه‌داده:  
- بخش آموزش: عمدتاً «دکترهست» و «نی‌نی‌بان»  
- بخش اعتبارسنجی: فقط «نی‌نی‌بان» (برای انسجام بیشتر)  
- بخش آزمون: «دکتریاب»، «ایزوویزیت» و ترجمه مجموعه‌داده K-QA  

خزش از تالار «دکترهست» با چالش خاصی همراه بود چون فقط به دو هزار رکورد آخر دسترسی مستقیم وجود داشت و بقیه از طریق لینک‌های مرتبط قابل دسترسی بودند. با استفاده از الگوریتم جستجوی عرض‌اول توانستیم حدود ۱۲۰ هزار رکورد را استخراج کنیم.

ترجمه بخش پزشکی مجموعه‌داده MMLU  
برای ارزیابی دقیق مدل‌ها، بخش پزشکی مجموعه‌داده معروف MMLU (سوالات چهارگزینه‌ای تخصصی) را به فارسی ترجمه کردیم (توسط دانشجوی پزشکی) و به‌صورت عمومی منتشر کردیم.

سوالات کنکور علوم پایه پزشکی ایران  
سوالات تمام دوره‌های آزمون علوم پایه پزشکی ایران را از فایل‌های پی‌دی‌اف سازمان سنجش استخراج کردیم و به‌صورت ساخت‌یافته منتشر کردیم.

ترجمه ماشینی مجموعه‌داده MedMCQA  
برای داشتن سوالات چندگزینه‌ای پزشکی به زبان فارسی، حدود ۱۸ هزار سوال از مجموعه‌داده بزرگ MedMCQA را با مدل DeepSeek-V3 به فارسی ترجمه کردیم. سپس با دو داور زبانی مستقل (مدل‌های grok-3-mini و gpt-4.1-mini) کیفیت ترجمه‌ها را بررسی کردیم و فقط مواردی که هر دو داور امتیاز کامل ۵ از ۵ دادند را نگه داشتیم.

مجموعه‌داده‌های PerMedCQA و PersianMedQA  
پس از انتشار داده‌های ما، دو مجموعه‌داده دیگر در حوزه پزشکی فارسی منتشر شد: PerMedCQA و PersianMedQA. ما ۱۰۰۰ پرسش تصادفی از بخش آموزشی PersianMedQA را به مجموعه خود اضافه کردیم تا تنوع منابع افزایش یابد. در نهایت مجموعه‌داده نهایی شامل ۱۹ هزار پرسش چندگزینه‌ای پزشکی فارسی (ترکیبی از ترجمه‌های تأییدشده MedMCQA و پرسش‌های PersianMedQA) شد.

تمام مجموعه‌داده‌ها و پیکره‌های ساخته‌شده در این فصل به‌صورت عمومی و باز در پلتفرم هاگینگ‌فیس منتشر شده‌اند تا پژوهشگران دیگر نیز بتوانند از آن‌ها استفاده کنند. این اقدام باعث شده جامعه فارسی‌زبان برای اولین بار به منابع باکیفیت و قابل دسترس در حوزه هوش مصنوعی پزشکی مجهز شود.

معرفی مدل زبانی گائوکرنا-V

مقدمه
در این فصل با استفاده از تمام دادگان گردآوری‌شده، یک مدل پزشکی فارسی به نام گائوکرنا-V می‌سازیم. این مدل هنوز توانایی استدلال واقعی ندارد و فقط دانش پزشکی فارسی را به‌خوبی درک و تولید می‌کند. در ادامه آن را با مدل پایه و سایر گزینه‌های موجود مقایسه می‌کنیم.

مدل پایه
چون هیچ مدل پزشکی فارسی متن‌باز وجود نداشت، از یک مدل همه‌منظوره به‌عنوان پایه استفاده کردیم. پس از بررسی گزینه‌های مختلف، مدل aya-expanse-8b را انتخاب کردیم به دو دلیل:
۱. تولید متن فارسی بسیار روان و درست (برخلاف بسیاری مدل‌های دیگر که حتی با دستور فارسی، حروف لاتین می‌نویسند).
۲. امکان ترکیب آسان با مدل aya-vision در آینده برای پذیرش تصاویر پزشکی (مانند ام‌آرآی و سی‌تی‌اسکن).

ویژگی‌های مدل aya-expanse
این مدل از ۲۳ زبان پشتیبانی می‌کند و در فارسی متن غنی و دستورزبان صحیح تولید می‌کند. برای جلوگیری از فروپاشی مدل هنگام استفاده از دادگان مصنوعی، از مکانیسم آربیتاژ داده استفاده کرده است.

تنظیم دقیق روی پیکره پزشکی
مدل پایه را روی ۶۰٪ پیکره پزشکی ۹۰ میلیونی توکنی تنظیم دقیق کردیم. برای کاهش مصرف حافظه:
- از روش لورا (رتبه ۸، آلفا ۱۶، حذف ۵٪، پوسیدگی وزن ۱۰٪)
- فلش‌اتنشن ۲
- اندازه دسته مؤثر ۳۲ (با تجمع گرادیان ۱۶ مرحله‌ای)
استفاده کردیم. این مرحله حدود ۱۹ ساعت روی یک کارت A100 طول کشید.

تنظیم دستورالعملی روی مجموعه‌داده MF3QA
سپس مدل را با روش لورا (رتبه ۲، آلفا ۲، حذف ۴۰٪، پوسیدگی وزن ۵۰٪) فقط یک دوره روی مجموعه‌داده MF3QA تنظیم کردیم تا یاد بگیرد چگونه به سؤالات پزشکی فارسی درست پاسخ دهد.

ردپای کربن
کل فرآیند آموزش حدود ۴٫۷۵ کیلووات‌ساعت انرژی مصرف کرد که معادل حدود ۲۶۶۰ گرم دی‌اکسید کربن است.

نتایج

مقایسه با مدل‌های فارسی همه‌منظوره
گائوکرنا-V اولین مدل فارسی زیر ۸ میلیارد پارامتر است که در کنکور علوم پایه پزشکی شهریور ۱۴۰۲ قبول شد (نمره ۳۸٫۶۹٪ بدون نمره منفی؛ حد نصاب قبولی ۳۶٪).
در بخش پزشکی مجموعه‌داده MMLU فارسی نیز میانگین ۴۹٫۳۱٪ گرفت که به‌طور قابل توجهی بهتر از مدل پایه و سایر مدل‌های فارسی بود.
در پرسش و پاسخ آزاد (با داور GPT-4o) نیز پاسخ‌های گائوکرنا-V در بیشتر موارد ترجیح داده شد.

مقایسه با روش‌های خط‌لوله‌ای (ترجمه + مدل انگلیسی + ترجمه مجدد)
این روش‌ها را با ترکیب MedMobile و مترجم‌های مختلف آزمایش کردیم. نتایج:
- دقت بسیار پایین (میانگین حدود ۲۰–۳۱٪)
- زمان پاسخ ۲–۳ برابر بیشتر (۲۰–۳۰ ثانیه در مقابل ۱۰ ثانیه)
- ترجمه بسیار ضعیف اصطلاحات تخصصی پزشکی
- نرخ پیروزی کمتر از ۱۰٪ در مقایسه مستقیم

نتیجه‌گیری
گائوکرنا-V اولین مدل پزشکی فارسی متن‌باز و قابل اجرا روی دستگاه محلی است که:
- در کنکور واقعی علوم پایه پزشکی قبول شد
- در تمام آزمون‌های دانش پزشکی فارسی از همه مدل‌های همه‌منظوره و روش‌های خط‌لوله‌ای به‌طور قاطع بهتر عمل کرد
- با هزینه بسیار کم (فقط ۱۹ ساعت روی یک A100) ساخته شد

این مدل پایه‌ای محکم برای افزودن توانایی استدلال واقعی در مرحله بعدی (گائوکرنا-R) فراهم می‌کند.


استدلال در مدل های زبانی

ظهور معماری ترنسفورمر در سال ۲۰۱۷ نقطه‌ی عطفی بنیادین در تحول مدل‌های زبانی بزرگ به‌شمار می‌آید. این معماری با معرفی سازوکار توجه و جایگزینی آن به‌جای پردازش متوالی، بسیاری از محدودیت‌های مدل‌های پیشین ــ از جمله پدیده‌ی محو شدن گرادیان‌ها و ناتوانی در مدل‌سازی وابستگی‌های بلندمدت ــ را برطرف ساخت. بدین‌ترتیب، امکان موازی‌سازی کامل در فرایند آموزش فراهم شد و مدل توانست ساختارهای زبانی پیچیده را با دقت و کارایی بسیار بالاتری درک و بازنمایی کند.
در این فصل، تمرکز بر بررسی توانایی استدلال در معماری ترنسفورمر و رویکردهای نوین برای بهبود آن است. هرچند این معماری در وظیفه‌ی پیش‌بینی توکن بعدی عملکردی خیره‌کننده دارد، اما نحوه‌ی استدلال آن عموما الگومحور است تا منطق‌محور. به بیان دیگر، تمامی مدل‌های زبانی مدرن که بر پایه‌ی ترنسفورمر ساخته شده‌اند، در هسته‌ی خود از همان ضعف بنیادی رنج می‌برند: ناتوانی در درک و بازتولید فرایندهای استدلالی عمیق و مبتنی بر منطق.

ناتوانی معماری ترنسفورمر در تفکر سیستم دو
در سال ۲۰۱۹، در یک کنفرانس، یوشوا بنجیو یکی از چهره‌های پیشگام حوزه‌ی یادگیری عمیق به یکی از محدودیت‌های بنیادین سیستم‌های یادگیری عمیق امروزی، از جمله مدل‌های زبانی، اشاره کرد: ناتوانی در انجام وظایفی که نیازمند مهارت‌های استدلالی قوی هستند.
به‌رغم عملکرد چشمگیر این سیستم‌ها در وظایف شهودی و ادراکی نظیر تشخیص تصویر، ترجمه‌ی ماشینی یا تولید متن، آن‌ها در مواجهه با مسائلی که مستلزم استدلال منطقی، درک روابط علّی و پردازش شناختی عمیق هستند، عملکرد ضعیفی از خود نشان می‌دهند. در واقع، بسیاری از اشتباهات ساده و احمقانه‌ی مدل‌های زبانی مانند ناتوانی در حل مسائل ریاضی ابتدایی یا استنتاج‌های منطقی آشکار را می‌توان با همین محدودیت در تفکر سیستم دو توضیح داد.
این مشاهده یادآور تمایز میان دو نوع تفکر است: تفکر سریع که بنجیو آن را تفکر سیستم یک می‌نامد و تفکر آهسته که او آن را تفکر سیستم دو می‌خواند. تفکر سریع شهودی، واکنشی و خودکار است و با نقاط قوت سیستم‌های فعلی هوش مصنوعی هم‌راستا است؛ در مقابل، تفکر آهسته فرایندی آگاهانه، تحلیلی و منطقی است که مستلزم توانایی در برنامه‌ریزی، استدلال و بازنمایی مفاهیم انتزاعی می‌باشد.
به بیان دیگر، شبکه‌های عصبی عمیق و مدل‌های مبتنی بر ترنسفورمر عمدتا در سطح تفکر سیستم یک عمل می‌کنند و فاقد شناخت منطقی یا استدلال علّی تفکر سیستم دو هستند. این شکاف میان شهود و منطق، چالشی اساسی در مسیر توسعه‌ی نسل بعدی مدل‌های زبانی و سامانه‌های هوش مصنوعی به شمار می‌رود.

طراحی یک معماری دارای قابلیت تفکر سیستم دو
بهترین رویکرد برای غلبه بر ناتوانی ترنسفورمرها در تفکر سیستم دو، توسعه‌ی یک معماری جدید است که بتواند این قابلیت را به‌طور ذاتی در خود داشته باشد. اما طراحی و پیاده‌سازی چنین معماری‌ای کار ساده‌ای نیست!
چنین معماری‌ای باید دارای توانایی تعمیم خارج از توزیع نیز باشد؛ به این معنا که مدل بتواند مفاهیم و روابطی را یاد بگیرد که به‌صورت صریح در داده‌های آموزشی وجود ندارند.
در سال‌های اخیر، پژوهشگران چندین مدل و معماری جایگزین برای بهبود توانایی استدلال پیشنهاد کرده‌اند، اما این مدل‌ها در عمل مقیاس‌پذیر نبوده و نتوانسته‌اند در مقیاس‌های بزرگ عملکرد قابل‌قبولی ارائه دهند.
در نتیجه، یکی از چالش‌های باز در حوزه‌ی یادگیری عمیق، یافتن معماری‌ای کارا، مقیاس‌پذیر و برخوردار از توان استدلال و تعمیم است؛ معماری‌ای که بتواند محدودیت‌های ذاتی ترنسفورمرها را پشت سر بگذارد.

بهبود توانایی دلیل‌آوری مدل‌های زبانی مبتنی بر ترنسفورمر
تا زمانی که معماری‌ای با قابلیت استدلال ذاتی در دسترس نداریم، ناچاریم با معماری ترنسفورمر کار کنیم و به‌نوعی بر محدودیت‌های آن غلبه کنیم.
با وجود پیشرفت‌ها، ترنسفورمرها هنوز فاقد سازوکار درونی برای استدلال گام‌به‌گام، تعمیم منطقی و درک علیت هستند. به همین دلیل، راهبرد عملی این است که به جای کنار گذاشتن آن‌ها، روش‌هایی برای تقویت توانایی استدلالی‌شان طراحی شود.
روش‌های گوناگونی برای این هدف پیشنهاد شده است. در این بخش، به بررسی مهم‌ترین روش‌هایی می‌پردازیم که می‌توانند توانایی استدلالی مدل‌های مبتنی بر ترنسفورمر را بهبود دهند.

روش‌های مبتنی بر هوش مصنوعی عصبی–نمادین
در هوش مصنوعی دو مکتب اصلی وجود دارد: نمادگرایی و ارتباط‌گرایی.
نمادگرایی بر منطق، قوانین و روابط صریح میان مفاهیم تکیه می‌کند و استدلال را بر پایه‌ی قواعد روشن انجام می‌دهد.
در مقابل، ارتباط‌گرایی بر یادگیری از داده استوار است و مدل‌ها الگوها را از میان داده‌ها استخراج می‌کنند.
با ظهور ترنسفورمر، ارتباط‌گرایی غالب شد، زیرا جمع‌آوری داده‌های عظیم ساده‌تر از استخراج قوانین دقیق است.
اما ترنسفورمرها در استدلال ناتوان‌اند.
برای رفع این شکاف، رویکرد عصبی–نمادین پیشنهاد شده است که ترکیبی از قدرت یادگیری مدل‌های عصبی و توان استدلال سیستم‌های نمادین است.
با این حال، بنجیو معتقد است که این مسیر راه‌حل نهایی نیست و بهترین راه، توسعه‌ی معماری‌هایی با قابلیت استدلال ذاتی است.

روش‌های مبتنی بر راهنمایی مدل زبانی توسط یک مدل پاداش
یکی از روش‌های تقویت استدلال، هدایت فرایند تولید پاسخ توسط یک مدل پاداش است.
مدل پاداش خروجی کیفیت پاسخ نهایی را ارزیابی می‌کند.
مدل پاداش فرایند، مراحل میانی استدلال را بررسی می‌کند تا مسیر استدلال منطقی باشد.
ترکیب این دو می‌تواند به پاسخ‌هایی درست و قابل‌اتکا منجر شود و مدل را به سمت تفکر گام‌به‌گام هدایت کند.

روش‌های مبتنی بر تمرین روی داده‌های استدلالی
در این رویکرد، مدل با داده‌هایی آموزش می‌بیند که حاوی نمونه‌هایی از فرایند استدلال هستند؛ مانند حل گام‌به‌گام مسائل، تحلیل منطقی و استدلال مبتنی بر شواهد.
مدل با این داده‌ها یاد می‌گیرد که فرایند استدلال را تقلید کند؛ در نتیجه به نظر می‌رسد که توان استدلالی دارد، در حالی که معماری آن فاقد استدلال ذاتی است.
این پدیده توهم دلیل‌آوری نامیده می‌شود.
یکی از موفق‌ترین مدل‌ها در این رویکرد، مدلی است که با داده‌های استدلالی گسترده آموزش دیده و توانسته عملکرد چشمگیری در وظایف استدلالی ارائه دهد.

معرفی مدل زبانی گائوکرنا-r
مقدمه
در این بخش، ما به معرفی مدل گائوکرنا-r می‌پردازیم. در این نسخه، دو روش نوین ارائه می‌شود که با استفاده از مقدار کمی داده می‌توانند توانایی‌های استدلالی مدل پایه را به‌صورت قابل‌توجهی بهبود بخشند. نتایج نشان می‌دهد که این رویکرد جدید عملکردی بهتر از نسخه قبلی دارد؛ مدلی که با حجم زیادی از داده‌ها آموزش دیده است. در ادامه، این فرضیه مطرح می‌شود که ارتقای مهارت‌های استدلالی در مدل‌های زبانی کوچک و کم‌منبع حوزه پزشکی، تأثیرگذارتر و سودمندتر از صرفا افزایش مقیاس داده‌ها است.

مدل پایه
به همان دلیلی که برای مدل نسخه قبلی، مدل دیگری را به‌عنوان مدل پایه انتخاب کردیم، برای مدل گائوکرنا نیز از همان مدل پایه استفاده می‌کنیم. هدف از این انتخاب، حفظ یک مبنای یکسان برای ارزیابی دقیق و منصفانه میان دو رویکرد است. دلیل دیگر این تصمیم، امکان مقایسه‌ی عادلانه میان آموزش مدل بر حجم عظیمی از داده‌ها و روش پیشنهادی ما برای بهبود مهارت‌های استدلالی است. با این کار، می‌توان به‌روشنی تأثیر واقعی افزایش توانایی استدلال در برابر صرفا گسترش داده‌های آموزشی را بررسی کرد و نشان داد که چگونه تقویت استدلال می‌تواند حتی در شرایط داده‌های محدود، موجب ارتقای عملکرد مدل شود.

به دلیل محدودیت‌های سخت‌افزاری و سرعت بالای چارچوب اول، مدل پایه را با چارچوب اول برای نود و پنج درصد داده‌ها و چارچوب دوم برای پنج درصد باقی‌مانده آموزش دادیم. این رویکرد، آموزش کارآمد با بهینه‌سازی ترجیح مستقیم را ممکن ساخت و شامل یازده هزار جفت پاسخ ترجیحی–ردشده با حدود دو میلیون توکن ترجیحی و دو و نیم میلیون توکن ردشده بود. این ترکیب، زمان آموزش را بهینه کرد و با بهره‌گیری از بازخورد دقیق چارچوب دوم، مهارت‌های استدلالی مدل را در مسائل پزشکی تقویت نمود.

متدهای معرفی‌شده
همان‌طور که پیش‌تر اشاره شد، برای تقویت مهارت‌های استدلالی در حوزه پزشکی، دو روش نوین معرفی شده‌اند. روش نخست سریع‌تر از روش دوم عمل می‌کند، اما روش دوم داده‌های باکیفیت‌تری برای آموزش تولید می‌نماید. در ادامه، به توضیح جزئیات این دو روش می‌پردازیم.

روش نخست
روش نخست از یک مدل معلم بهره می‌گیرد. این مدل معلم، خود یک مدل زبانی با قابلیت استدلال پیشرفته است که وظیفه دارد خطاهای استدلالی مدل دانش‌آموز را در پاسخ به پرسش‌های چندگزینه‌ای حوزه پزشکی شناسایی و اصلاح کند. در این فرایند، اگر مدل دانش‌آموز گزینه‌ی صحیح را انتخاب کند، بدون نیاز به مداخله‌ی بیشتر، به سؤال بعدی منتقل می‌شویم. اما در صورتی که پاسخ نادرست باشد، مدل معلم با در نظر گرفتن پاسخ درست، یک توضیح گام‌به‌گام و دقیق در قالب زنجیره استدلال تولید می‌کند. این توضیحات نه‌تنها اشتباه مدل دانش‌آموز را مشخص می‌کنند، بلکه نحوه‌ی استدلال صحیح در مسائل پزشکی را نیز آموزش می‌دهند. در این سازوکار، خروجی مدل معلم به‌عنوان پاسخ برگزیده تلقی می‌شود و پاسخ اولیه‌ی مدل دانش‌آموز به‌عنوان پاسخ مردود برای فرایند بهینه‌سازی مستقیم ترجیحات مورد استفاده قرار می‌گیرد.

الگوریتم روش نخست:
– پرسش‌های پزشکی از مدل دانش‌آموز پرسیده می‌شود.
– اگر پاسخ درست بود، پرسش حذف می‌شود.
– پاسخ نادرست ذخیره می‌شود.
– مدل معلم پاسخ درست همراه با استدلال را تولید می‌کند.
– جفت پاسخ درست و نادرست ذخیره می‌شود.
– در صورت جمع شدن جفت‌های کافی، مدل دانش‌آموز با روش ترجیح مستقیم آموزش داده می‌شود.

روش دوم
روش دوم نیز از مدل معلم استفاده می‌کند، اما بازخورد دقیق‌تری ارائه می‌دهد. این روش با شناسایی خطای خاص در پاسخ مدل دانش‌آموز عمل می‌کند. مدل دانش‌آموز تشویق می‌شود پاسخ خود را دقیقا از نقطه‌ای که خطا رخ داده، اصلاح کند. از طریق تکرار این روند، مدل دانش‌آموز به‌تدریج مسیر استدلالی خود را بهبود می‌بخشد و به پاسخ صحیح همگرا می‌شود. این بازخورد سازنده باعث می‌شود مدل دانش‌آموز استقلال استدلالی بیشتری کسب کند. در این فرایند، پاسخ نهایی مدل دانش‌آموز به‌عنوان پاسخ ترجیحی و تلاش اولیه او به‌عنوان پاسخ ردشده برای آموزش ترجیح مستقیم استفاده می‌شود. اگرچه این چارچوب زمان‌برتر است، اما داده‌های باکیفیت‌تری تولید می‌کند.

الگوریتم روش دوم:
– پرسش از مدل دانش‌آموز پرسیده می‌شود.
– اگر پاسخ درست نبود، ذخیره می‌شود.
– تا زمانی که پاسخ درست نشده، مدل معلم خطا را گزارش می‌کند و مدل دانش‌آموز دوباره پاسخ می‌دهد.
– پاسخ نهایی و اولیه ذخیره می‌شوند.
– پس از گردآوری داده کافی، آموزش ترجیح مستقیم انجام می‌شود.

ردپای کربن
ردپای کربنی فرایند تمرین مدل گائوکرنا بر اساس پیکربندی سخت‌افزاری و مدت‌زمان کل اجرا برآورد شده است. مدل به‌مدت حدود یک ساعت بر روی یک کارت گرافیک با هشتاد گیگابایت حافظه آموزش داده شد و چهل و سه گیگابایت حافظه استفاده شد. با توان مصرفی حدود سیصد و پنجاه وات، میزان انرژی مصرفی حدود 0.35 کیلووات‌ساعت و مقدار انتشار کربن حدود سی گرم دی‌اکسید کربن برآورد می‌شود. این میزان در مقایسه با نسخه قبلی که حدود دو و شصت‌و‌شش صدم کیلوگرم دی‌اکسید کربن تولید کرده بود، کاهش چشمگیری دارد.

نتایج
در این بخش، مدل گائوکرنا با نسخه قبلی مقایسه می‌شود. نسخه قبلی بر مجموعه داده‌های بسیار بزرگ آموزش دیده و دانش پزشکی گسترده‌ای دارد، اما نسخه جدید برای تقویت استدلال طراحی شده است. اگرچه داده‌های کمی داشته، توانسته استدلال عمیق‌تری ارائه دهد. نتایج نشان می‌دهد که نسخه جدید با وجود مقیاس کوچک‌تر، از طریق هدایت استدلال ساختاریافته عملکرد بهتری دارد.

سنجش استدلال پزشکی
برای ارزیابی استدلال، از مدل‌ها خواسته شد مسیرهای زنجیره فکری تولید کنند. برای هر پرسش، پنج نمونه تولید شد و با رأی اکثریت پاسخ نهایی تعیین شد. نتایج نشان داد مدل گائوکرنا-R در اکثر دسته‌ها بهتر عمل می‌کند.

معیار Pass@k نیز برای دو مجموعه‌داده محاسبه شد. نتایج نشان داد نسخه جدید عملکرد پایدارتر و مطمئن‌تری دارد، در حالی که نسخه قبلی با افزایش k بهبود می‌یابد اما در مقادیر کوچک‌تر عملکرد ضعیف‌تری دارد.

سنجش دانش پزشکی
در ارزیابی با درخواست مستقیم، نسخه قبلی عملکرد بهتری دارد، زیرا دانش پزشکی گسترده‌تری دارد. نسخه جدید و مدل پایه در این بخش عملکرد مشابهی دارند.

سنجش پایانی
در جمع‌بندی، نسخه قبلی در درخواست مستقیم بهتر است، اما نسخه جدید در زنجیره افکار عملکرد برتری دارد. با ترکیب نسخه جدید با مدل پایه به‌عنوان تأییدکننده کمکی، نتایج بهبود بیشتری نشان می‌دهد.

نتیجه گیری
در این پایان‌نامه، علاوه بر جمع‌آوری و معرفی مجموعه‌داده پزشکی فارسی، دو مدل زبانی کوچک تخصصی پزشکی نیز آموزش داده و ارائه شدند. نتایج به‌دست‌آمده نشان‌دهنده عملکرد مطلوب این مدل‌ها است و می‌توانند به‌عنوان گام‌های اولیه در مسیر توسعه مدل‌های زبانی کوچک و کارآمد پزشکی به زبان فارسی محسوب شوند.

نوآوری های این پایان نامه به شرح زیر است:

معرفی اولین مدل های زبانی پزشکی فارسی منبع‌باز که در مقایسه با سایر مدل‌های قابل اجرا روی دستگاه‌های خانگی مانند لپ‌تاپ و کامپیوتر شخصی به نتایج امیدوارکننده دست یافته است.

معرفی یک پیکرهٔ پزشکی فارسی که از طریق خزش وب‌سایت‌های مختلف پزشکی جمع‌آوری شده است.

معرفی اولین مجموعه‌داده پرسش و پاسخ پزشکی فارسی فرم آزاد که از طریق خزش سایت‌های پرسش و پاسخ پزشکی جمع‌آوری شده است.

ترجمه بخش پزشکی مجموعه داده به زبان فارسی که می‌تواند به‌عنوان یک معیار استاندارد و قابل اعتماد برای ارزیابی هر مدل زبانی پزشکی فارسی مورد استفاده قرار گیرد.

معرفی چارچوب های کارآمد که با استفاده از یک حلقه آموزگار–شاگرد باعث بهبود توانایی دلیل آوری مدل زبانی شاگرد می‌شوند.

تحقیقات آینده
هرچند مدل های معرفی شده در مقایسه با مدل پایه و سایر گزینه‌های موجود، دانش پزشکی فارسی به‌مراتب بهتری از خود نشان می‌دهد، اما عملکرد فعلی آن هنوز به سطحی نرسیده است که بتوان آن را به‌طور قابل اعتماد در سناریوهای بالینی واقعی به کار گرفت.

در تحقیقات آینده پارامترهای به‌روز‌شدهٔ خود را به‌جای استفاده از مدل قبلی، با یک مدل جدید ادغام می‌کنیم تا مدل قادر به پذیرش ورودی‌های چندوجهی نظیر تصاویر پزشکی شود. با این حال، توانایی مدل در پردازش پرسش‌های چندوجهی هنوز به‌طور جامع بررسی نشده است.

در تحقیقات آتی، تمرکز اصلی ما بر بهبود توانایی مدل در درک و هم‌راستا کردن اطلاعات متنی و بصری خواهد بود تا کاربرد تشخیصی و تحلیلی آن در پزشکی گسترش یابد. همچنین، کارهای آینده شامل همکاری نزدیک با پزشکان واقعی برای بهبود مدل از طریق یادگیری تقویتی مبتنی بر بازخورد انسانی و اعتبارسنجی بالینی دقیق خواهد بود تا ایمنی و قابلیت استفاده عملی مدل در محیط‌های واقعی مراقبت‌های بهداشتی تضمین شود.

استدلال در مدل های زبانی
ظهور معماری ترنسفورمر در سال ۲۰۱۷ نقطه‌ی عطفی بنیادین در تحول مدل‌های زبانی بزرگ به‌شمار می‌آید. این معماری با معرفی سازوکار توجه و جایگزینی آن به‌جای پردازش متوالی، بسیاری از محدودیت‌های مدل‌های پیشین ــ از جمله پدیده‌ی محو شدن گرادیان‌ها و ناتوانی در مدل‌سازی وابستگی‌های بلندمدت ــ را برطرف ساخت. بدین‌ترتیب، امکان موازی‌سازی کامل در فرایند آموزش فراهم شد و مدل توانست ساختارهای زبانی پیچیده را با دقت و کارایی بسیار بالاتری درک و بازنمایی کند.

در این فصل، تمرکز بر بررسی توانایی استدلال در معماری ترنسفورمر و رویکردهای نوین برای بهبود آن است. هرچند این معماری در وظیفه‌ی پیش‌بینی توکن بعدی عملکردی خیره‌کننده دارد، اما نحوه‌ی استدلال آن عموماً الگومحور است تا منطق‌محور. به بیان دیگر، تمامی مدل‌های زبانی مدرن که بر پایه‌ی ترنسفورمر ساخته شده‌اند، در هسته‌ی خود از همان ضعف بنیادی رنج می‌برند: ناتوانی در درک و بازتولید فرایندهای استدلالی عمیق و مبتنی بر منطق.

ناتوانی معماری ترنسفورمر در تفکر سیستم دو
در سال ۲۰۱۹، در یک کنفرانس، یوشوا بنجیو یکی از چهره‌های پیشگام در حوزه‌ی یادگیری عمیق به یکی از محدودیت‌های بنیادین سیستم‌های یادگیری عمیق امروزی، از جمله مدل‌های زبانی، اشاره کرد: ناتوانی در انجام وظایفی که نیازمند مهارت‌های استدلالی قوی هستند.
به‌رغم عملکرد چشمگیر این سیستم‌ها در وظایف شهودی و ادراکی نظیر تشخیص تصویر، ترجمه‌ی ماشینی یا تولید متن، آن‌ها در مواجهه با مسائلی که مستلزم استدلال منطقی، درک روابط علّی و پردازش شناختی عمیق هستند، عملکرد ضعیفی از خود نشان می‌دهند. بسیاری از اشتباهات ساده و کودکانه‌ی مدل‌های زبانی مانند ناتوانی در حل مسائل ریاضی ابتدایی یا استنتاج‌های منطقی آشکار را می‌توان با همین محدودیت در تفکر سیستم دو توضیح داد.

این مشاهده یادآور تمایز مطرح‌شده در علوم شناختی میان دو نوع تفکر است: تفکر سریع که بنجیو آن را «تفکر سیستم یک» می‌نامد و تفکر آهسته که او آن را «تفکر سیستم دو» می‌خواند. تفکر سریع ماهیتی شهودی، واکنشی و خودکار دارد و با نقاط قوت سیستم‌های فعلی هوش مصنوعی هم‌راستا است؛ در مقابل، تفکر آهسته فرایندی آگاهانه، تحلیلی و منطقی است که مستلزم توانایی در برنامه‌ریزی، استدلال و بازنمایی مفاهیم انتزاعی می‌باشد.
به بیان دیگر، شبکه‌های عصبی عمیق و به‌ویژه مدل‌های زبانی مبتنی بر ترنسفورمر عمدتاً در سطح تفکر سیستم یک، یعنی شناخت شهودی، عمل می‌کنند و فاقد شناخت منطقی یا استدلال علّی تفکر سیستم دو هستند. این شکاف میان شهود و منطق، چالشی اساسی در مسیر توسعه‌ی نسل بعدی مدل‌های زبانی و سامانه‌های هوش مصنوعی با قابلیت تفکر مشابه انسان به شمار می‌رود.

طراحی یک معماری دارای قابلیت تفکر سیستم دو
بهترین رویکرد برای غلبه بر ناتوانی ترنسفورمرها در تفکر سیستم دو، توسعه‌ی یک معماری جدید است که بتواند این قابلیت را به‌طور ذاتی در خود داشته باشد. اما طراحی و پیاده‌سازی چنین معماری‌ای کار ساده‌ای نیست.

چنین معماری‌ای باید دارای توانایی تعمیم خارج از توزیع نیز باشد؛ به این معنا که مدل بتواند مفاهیم و روابطی را یاد بگیرد که به‌صورت صریح و مستقیم در داده‌های آموزشی وجود ندارند. به بیان دیگر، سیستم باید قادر باشد از دانش موجود در داده‌ها به موقعیت‌های جدید و نادیده تعمیم دهد ــ ویژگی‌ای که برای استدلال واقعی و تفکر سطح بالا ضروری است.

در سال‌های اخیر، پژوهشگران چندین مدل و معماری جایگزین را برای بهبود توانایی استدلال در شبکه‌های عصبی پیشنهاد داده‌اند. برای مثال، یکی از این تلاش‌ها معماری‌ای بود که توسط یوشوا بنجیو معرفی شد. یا معماری مدل استدلال سلسله‌مراتبی که با الهام از سلسله‌مراتبی بودن تفکر انسان پیشنهاد شده است.

با این حال، مدل‌های پیشنهادشده در عمل معماری مقیاس‌پذیری نبوده و نتوانسته‌اند در مقیاس‌های بزرگ عملکرد قابل‌قبولی ارائه دهند. به همین دلیل، نمی‌توان آن‌ها را یک پیشنهاد موفق برای حل مشکل استدلال در مدل‌های مبتنی بر ترنسفورمر دانست.

در نتیجه، همچنان یکی از چالش‌های باز در حوزه‌ی یادگیری عمیق و مدل‌های زبانی بزرگ، یافتن معماری‌ای کارا، مقیاس‌پذیر، دارای توان استدلالی و برخوردار از قابلیت تعمیم خارج از توزیع است؛ معماری‌ای که بتواند محدودیت‌های ذاتی ترنسفورمرها را پشت سر بگذارد.

بهبود توانایی دلیل آوری مدل های زبانی مبتنی بر ترنسفورمر
تا زمانی که هنوز معماری‌ای با قابلیت استدلال ذاتی در دسترس نداریم، ناچاریم همچنان با معماری ترنسفورمر کار کنیم و به‌نوعی بر محدودیت‌ها و ضعف‌های ذاتی آن غلبه نماییم.

با وجود تمام پیشرفت‌ها، ترنسفورمرها هنوز فاقد سازوکار درونی برای استدلال گام‌به‌گام، تعمیم منطقی و درک علیت هستند. با این حال، از آن‌جا که در حال حاضر موثرترین و مقیاس‌پذیرترین معماری در حوزه‌ی مدل‌های زبانی محسوب می‌شوند، راهبرد عملی این است که به جای کنار گذاشتن آن‌ها، راهکارهایی برای تقویت توانایی استدلالی‌شان طراحی و به کار گرفته شود. روش‌های گوناگونی برای این هدف پیشنهاد شده است که برای اطلاعات بیشتر می‌توان به یک مقاله مروری در این زمینه مراجعه کرد.

در این بخش، به بررسی مهم‌ترین این رویکردها و روش‌هایی که می‌توانند به بهبود توانایی استدلالی مدل‌های مبتنی بر ترنسفورمر منجر شوند، خواهیم پرداخت.

روش های مبتنی بر هوش مصنوعی عصبی–نمادین
در حوزه‌ی هوش مصنوعی، دو مکتب فکری اصلی وجود دارد: نمادگرایی و ارتباط‌گرایی.

در مکتب نمادگرایی، هدف اصلی این است که منطق، قوانین و روابط صریح میان مفاهیم جمع‌آوری شود و در قالب یک مدل منطقی یا قاعده‌محور نمایش داده شود. این رویکرد بر پایه‌ی استدلال نمادین استوار است.

در مقابل، مکتب ارتباط‌گرایی بر پایه‌ی ایده‌ی یادگیری از داده‌ها شکل گرفته است. در این رویکرد، به‌جای تعریف قوانین منطقی، حجم زیادی از داده به مدل داده می‌شود تا خود سیستم از درون داده‌ها الگوها و روابط را کشف کند. شبکه‌های عصبی مصنوعی و مدل‌های عمیق از نمونه‌های شاخص این مکتب هستند.

با معرفی معماری ترنسفورمر، مکتب ارتباط‌گرایی به شکل چشمگیری غالب شد و تقریباً تمامی پژوهش‌های پیشرفته‌ی حوزه‌ی هوش مصنوعی حول آن متمرکز گردید. جمع‌آوری داده‌های عظیم بسیار ساده‌تر از استخراج و تعریف قوانین منطقی دقیق است.

با این حال، همان‌طور که پیش‌تر اشاره شد، ترنسفورمرها ضعف بزرگی دارند: ناتوانی در استدلال!
این مدل‌ها اگرچه در شناسایی الگوها و پیش‌بینی توالی‌ها بسیار قدرتمندند، اما فاقد سازوکار درونی برای انجام استدلال منطقی و تفکر نظام‌مند هستند.
در مقابل، رویکردهای نمادین توانایی استدلال ذاتی دارند اما مشکل بزرگ آن‌ها عدم مقیاس‌پذیری است.

برای رفع این شکاف، رویکرد عصبی–نمادین مطرح شده است. در این دیدگاه تلاش می‌شود از قدرت یادگیری مدل‌های عصبی در کنار توان استدلال سیستم‌های نمادین استفاده شود تا هوشی ترکیبی ایجاد گردد. با این حال، بنجیو معتقد است این مسیر راه‌حل نهایی نیست و بهترین راه، توسعه‌ی معماری‌هایی است که قابلیت استدلال را به‌طور ذاتی در درون خود داشته باشند.

روش های مبتنی بر هدایت مدل زبانی توسط یک مدل پاداش
یکی از روش‌های بهبود مهارت‌های استدلالی یک مدل زبانی، هدایت فرآیند رمزگشایی آن با استفاده از یک مدل پاداش است. مدل پاداش می‌تواند به دو صورت باشد: مدل پاداش خروجی و مدل پاداش فرآیند.

مدل پاداش خروجی کیفیت پاسخ نهایی تولیدشده را ارزیابی می‌کند. مدل پاداش فرآیند مراحل میانی استدلال را بررسی می‌کند تا مسیر استدلال منطقی باشد. استفاده از این دو مدل پاداش می‌تواند عملکرد مدل را در وظایف پیچیده بهبود دهد.

یکی از تلاش‌ها در این زمینه مدلی است که در بخش کارهای پیشین توضیح داده شده است.

روش های مبتنی بر تمرین روی داده های دلیل آوری
یکی دیگر از روش‌های بهبود مهارت‌های استدلالی یک مدل زبانی، آموزش آن با داده‌های استدلالی است. در این روش مدل یاد می‌گیرد فرآیند استدلالی را تقلید کند یا بازتولید نماید. داده‌ها شامل نمونه‌هایی از حل گام‌به‌گام مسائل، تحلیل‌های منطقی و استدلال‌های مبتنی بر شواهد هستند.

این فرایند کمک می‌کند مدل پاسخ‌هایی منطقی‌تر ارائه دهد. اما این استدلال واقعی نیست، بلکه شبیه‌سازی است که گاهی به آن «توهم دلیل‌آوری» گفته می‌شود.

یکی از مهم‌ترین کارهایی که این رویکرد را با موفقیت به‌کار گرفته، یک مدل است که با استفاده از مجموعه داده‌های استدلالی گسترده آموزش دیده و توانسته عملکرد چشمگیری در وظایف پیچیده نشان دهد. این مدل قادر است استدلال‌های منطقی را با دقت بالا تولید کند و در مسائل چندمرحله‌ای عملکرد قابل‌توجهی ارائه دهد.

‫اﺟﺮای ‬‫ﻣﺪل‬ ‫ﻫﺎی‬ ‫زﺑﺎﻧﯽ‬
وزن های مدل های معرفی شده به صورت عمومی منتشر شده است. برای دریافت آن می‌توانید به مخزن مربوط مراجعه کنید.
برای اجرای این مدل ها می‌توانید از برنامه اشاره‌شده برای دادن تنها متن به ورودی و از برنامه دیگر برای دادن متن و تصویر به ورودی استفاده کنید.

کیفیت پاسخ‌دهی مدل در حالت چندوجهی (ورودی همزمان متن و تصویر) در چارچوب این پایان‌نامه به صورت جامع ارزیابی نشده است و نتایج ممکن است بسته به کیفیت تصویر، وضوح تصویر و نوع پرسش متفاوت باشد. بنابراین توصیه می‌شود در کاربردهای حساس ابتدا ارزیابی‌های اضافی انجام دهید.

















